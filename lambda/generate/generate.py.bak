"""
ì„œìš¸ê²½ì œì‹ ë¬¸ AI ìš”ì•½ ì‹œìŠ¤í…œ - REST API ì—”ë“œí¬ì¸íŠ¸
ê³µí†µ ë¡œì§ì€ core_processor.pyë¡œ ë¶„ë¦¬í•˜ì—¬ ì¤‘ë³µ ì œê±°
"""

import json
import boto3
import os
import logging
import traceback
from datetime import datetime
import sys
from pathlib import Path

# ê³µí†µ ì²˜ë¦¬ ëª¨ë“ˆ import
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent.parent / 'utils'))

try:
    from core_processor import get_news_processor
    from common_utils import DecimalEncoder
except ImportError as e:
    logger.error(f"ëª¨ë“ˆ import ì˜¤ë¥˜: {e}")

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# í™˜ê²½ ë³€ìˆ˜
MODEL_ID = "anthropic.claude-3-sonnet-20240229-v1:0"

def lambda_handler(event, context):
    """ë©”ì¸ Lambda í•¸ë“¤ëŸ¬ - REST API ë°©ì‹"""
    try:
        logger.info(f"ğŸ“ REST API ìš”ì²­ ì‹œì‘: {json.dumps(event, ensure_ascii=False)[:200]}")
        
        # ìš”ì²­ íŒŒì‹±
        http_method = event.get("httpMethod", "POST")
        path = event.get("path", "")
        
        # ìš”ì²­ ë³¸ë¬¸ íŒŒì‹±
        body = {}
        if http_method == 'POST':
            try:
                body = json.loads(event.get('body', '{}'))
            except json.JSONDecodeError:
                return _create_error_response(400, "ì˜ëª»ëœ JSON í˜•ì‹ì…ë‹ˆë‹¤.")
        else:
            body = event.get('queryStringParameters') or {}
        
        user_input = body.get('userInput', '').strip()
        chat_history = body.get('chat_history', [])
        model_id = body.get('modelId', MODEL_ID)
        
        if not user_input:
            return _create_error_response(400, "ì‚¬ìš©ì ì…ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ê³µí†µ ì²˜ë¦¬ ë¡œì§ ì‚¬ìš©
        news_processor = get_news_processor()
        
        # ìŠ¤íŠ¸ë¦¬ë° vs ì¼ë°˜ ì‘ë‹µ ë¶„ê¸°
        if "/stream" in path:
            return _handle_streaming_generation(news_processor, user_input, chat_history, model_id)
        else:
            return _handle_standard_generation(news_processor, user_input, chat_history, model_id)
            
    except Exception as e:
        logger.error(f"âŒ Handler ì˜¤ë¥˜: {str(e)}")
        logger.error(f"âŒ Traceback: {traceback.format_exc()}")
        return _create_error_response(500, f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {e}")

def _handle_standard_generation(news_processor, user_input, chat_history, model_id):
    """ì¼ë°˜ ìƒì„± ì²˜ë¦¬ - ê³µí†µ ë¡œì§ í™œìš©"""
    try:
        logger.info(f"ğŸ“ ì¼ë°˜ ìƒì„± ì‹œì‘: {user_input[:50]}...")
        
        # ê³µí†µ ì²˜ë¦¬ ì—”ì§„ìœ¼ë¡œ ì „ì²´ í”Œë¡œìš° ì‹¤í–‰
        result = news_processor.process_complete_flow(user_input, chat_history, model_id)
        
        if not result['success']:
            return _create_error_response(500, f"ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result['error']}")
        
        return {
            'statusCode': 200,
            'headers': _get_cors_headers(),
            'body': json.dumps({
                'success': True,
                'response': result['response'],
                'model': model_id,
                'timestamp': datetime.now().isoformat()
            }, ensure_ascii=False, cls=DecimalEncoder)
        }
        
    except Exception as e:
        logger.error(f"âŒ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return _create_error_response(500, f"ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def _handle_streaming_generation(news_processor, user_input, chat_history, model_id):
    """ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì²˜ë¦¬ - SSE ë°©ì‹ìœ¼ë¡œ RESTì—ì„œë„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›"""
    try:
        logger.info(f"ğŸŒŠ REST ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì‹œì‘: {user_input[:50]}...")
        
        # 1ë‹¨ê³„: ë‚ ì§œ ì •ì˜ ë° ì§ˆë¬¸ ë³´ê°•
        enhanced_query = news_processor.enhance_query_with_date(user_input)
        streaming_body = f"data: {json.dumps({'status': 'processing', 'message': 'ì§ˆë¬¸ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
        
        # 2ë‹¨ê³„: AWS ë‚´ë¶€ ì§€ì‹ ê²€ìƒ‰
        streaming_body += f"data: {json.dumps({'status': 'searching', 'message': 'ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
        knowledge_context = news_processor.search_knowledge_base(enhanced_query)
        
        # 3ë‹¨ê³„: í•„ìš”ì‹œ ì™¸ë¶€ ê²€ìƒ‰
        if news_processor.should_use_external_search(knowledge_context, user_input):
            streaming_body += f"data: {json.dumps({'status': 'external_searching', 'message': 'ìµœì‹  ì •ë³´ë¥¼ ì¶”ê°€ë¡œ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
            external_context = news_processor.search_external_knowledge(enhanced_query)
            knowledge_context += f"\n\n[ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼]\n{external_context}"
        
        # 4ë‹¨ê³„: ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        final_prompt = news_processor.build_final_prompt(user_input, chat_history, knowledge_context)
        
        # 5ë‹¨ê³„: ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
        streaming_body += f"data: {json.dumps({'status': 'generating', 'message': 'ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
        
        # Bedrock ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
        bedrock_runtime = boto3.client(
            service_name='bedrock-runtime',
            region_name=os.environ.get('AWS_REGION', 'ap-northeast-2')  # ì„œìš¸ë¦¬ì „ìœ¼ë¡œ ë³€ê²½
        )
        
        request_body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 4000,
            "temperature": 0.1,
            "messages": [{"role": "user", "content": final_prompt}]
        }
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        response = bedrock_runtime.invoke_model_with_response_stream(
            modelId=model_id,
            contentType='application/json',
            accept='application/json',
            body=json.dumps(request_body)
        )
        
        # SSE í˜•ì‹ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬ì„±
        for event in response['body']:
            chunk = json.loads(event['chunk']['bytes'])
            if chunk['type'] == 'content_block_delta':
                text = chunk['delta'].get('text', '')
                if text:
                    sse_chunk = f"data: {json.dumps({'text': text}, ensure_ascii=False)}\n\n"
                    streaming_body += sse_chunk
        
        # ì™„ë£Œ ë©”ì‹œì§€
        streaming_body += f"data: {json.dumps({'status': 'completed', 'message': 'ë‹µë³€ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'}, ensure_ascii=False)}\n\n"
        streaming_body += "data: [DONE]\n\n"
        
        return {
            'statusCode': 200,
            'headers': {
                **_get_cors_headers(),
                'Content-Type': 'text/event-stream',
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive'
            },
            'body': streaming_body
        }
        
    except Exception as e:
        logger.error(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {str(e)}")
        return _create_error_response(500, f"ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def _create_error_response(status_code, message):
    """ì—ëŸ¬ ì‘ë‹µ ìƒì„±"""
    return {
        'statusCode': status_code,
        'headers': _get_cors_headers(),
        'body': json.dumps({
            'success': False,
            'error': message,
            'timestamp': datetime.now().isoformat()
        }, ensure_ascii=False)
    }

def _get_cors_headers():
    """CORS í—¤ë”"""
    return {
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
        'Access-Control-Allow-Headers': 'Content-Type, Authorization, X-Requested-With',
    } 