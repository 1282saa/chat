"""
ì„ê³„ê°’ ê¸°ë°˜ ì¡°ê±´ë¶€ ì‹¤í–‰ ì—”ì§„ (Conditional Execution Engine)
- ëª¨ë“  ì—ì´ì „íŠ¸ë“¤ì˜ ì¤‘ì•™ ì›Œí¬í”Œë¡œìš° ì œì–´
- ì„ê³„ê°’ ê¸°ë°˜ ë¶„ê¸° ë¡œì§
- ì¬ì‹œë„ ë° í’ˆì§ˆ ê´€ë¦¬
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
"""
import json
import os
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import boto3
from enum import Enum

# ìƒëŒ€ import (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
import sys
sys.path.append('..')

logger = logging.getLogger()
logger.setLevel(logging.INFO)

class ExecutionStatus(Enum):
    """ì‹¤í–‰ ìƒíƒœ ì—´ê±°í˜•"""
    PENDING = "pending"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"
    RETRY = "retry"

class ThresholdType(Enum):
    """ì„ê³„ê°’ ìœ í˜•"""
    QUALITY = "quality"
    COVERAGE = "coverage"
    FRESHNESS = "freshness"
    CLARITY = "clarity"
    CONFIDENCE = "confidence"

class ConditionalExecutionEngine:
    """
    ëª¨ë“  ì—ì´ì „íŠ¸ë¥¼ ì œì–´í•˜ëŠ” ì¤‘ì•™ ì›Œí¬í”Œë¡œìš° ì—”ì§„
    """
    
    def __init__(self):
        # ì„ê³„ê°’ ì„¤ì • (ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ë°˜ì˜)
        self.thresholds = {
            ThresholdType.QUALITY: 0.85,      # ë‹µë³€ í’ˆì§ˆ (ì¬ìƒì„± í•„ìš”)
            ThresholdType.COVERAGE: 0.7,      # ë‚´ë¶€ ì§€ì‹ ì»¤ë²„ë¦¬ì§€ (ì™¸ë¶€ ê²€ìƒ‰ í•„ìš”)
            ThresholdType.FRESHNESS: 0.6,     # ì‹ ì„ ë„ ìš”êµ¬ì‚¬í•­ (ì‹¤ì‹œê°„ ì •ë³´ í•„ìš”)
            ThresholdType.CLARITY: 0.8,       # ì§ˆë¬¸ ëª…í™•ì„± (ì¬ì§ˆë¬¸ í•„ìš”)
            ThresholdType.CONFIDENCE: 0.75    # ì „ì²´ ì‹ ë¢°ë„
        }
        
        # ì¬ì‹œë„ ì„¤ì •
        self.retry_config = {
            "max_retries": 3,
            "retry_delay": 2,  # ì´ˆ
            "exponential_backoff": True
        }
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance_metrics = {
            "total_executions": 0,
            "successful_executions": 0,
            "failed_executions": 0,
            "retry_executions": 0,
            "avg_execution_time": 0.0,
            "external_search_rate": 0.0
        }
        
        # DynamoDB ë©”íŠ¸ë¦­ ì €ì¥
        self.dynamodb = boto3.client("dynamodb", region_name=os.environ.get("REGION", "ap-northeast-2"))
        self.metrics_table = os.environ.get("EXECUTION_METRICS_TABLE", "workflow-execution-metrics")
        
        # ì—ì´ì „íŠ¸ ì„í¬íŠ¸ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì ì ˆíˆ ìˆ˜ì •)
        self.agents = {}
        self._initialize_agents()
    
    def _initialize_agents(self):
        """ì‹¤ì œ Enhanced Agent System ì´ˆê¸°í™”"""
        try:
            # ì‹¤ì œ ì—ì´ì „íŠ¸ë“¤ import ì‹œë„
            logger.info("ğŸ”„ ì‹¤ì œ Enhanced ì—ì´ì „íŠ¸ë“¤ ë¡œë“œ ì‹œì‘...")
            
            from react_planning.react_agent import ReactPlanningAgent
            from date_intelligence.date_processor import DateIntelligenceProcessor  
            from external_search.perplexity_integration import PerplexitySearchAgent
            
            # ì‹¤ì œ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            self.agents = {
                "planner": ReactPlanningAgent(),
                "date_processor": DateIntelligenceProcessor(),
                "external_search": PerplexitySearchAgent()
            }
            
            logger.info("âœ… ì‹¤ì œ Enhanced Agent System ì´ˆê¸°í™” ì™„ë£Œ!")
            logger.info("ğŸ¯ í™œì„±í™”ëœ ì—ì´ì „íŠ¸ë“¤:")
            logger.info("   - ReactPlanningAgent (ReAct + CoT)")
            logger.info("   - DateIntelligenceProcessor (ë‚ ì§œ ì§€ëŠ¥í˜• ì²˜ë¦¬)")
            logger.info("   - PerplexitySearchAgent (ì™¸ë¶€ ê²€ìƒ‰)")
            
        except ImportError as e:
            logger.warning(f"âš ï¸ ì‹¤ì œ ì—ì´ì „íŠ¸ ì„í¬íŠ¸ ì‹¤íŒ¨, Mock ì—ì´ì „íŠ¸ë¡œ Fallback")
            logger.warning(f"   Import ì˜¤ë¥˜: {str(e)}")
            logger.warning(f"   Python ê²½ë¡œ: {sys.path}")
            
            # Fallback: Mock ì—ì´ì „íŠ¸ë“¤ ì‚¬ìš©
            self.agents = {
                "planner": self._create_simple_planner(),
                "date_processor": self._create_simple_date_processor(),
                "external_search": self._create_simple_external_search()
            }
            logger.info("ğŸ“ Mock ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (Fallback ëª¨ë“œ)")
            
        except Exception as e:
            logger.error(f"âŒ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            logger.error(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
            import traceback
            logger.error(f"   ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            
            # Fallback: Mock ì—ì´ì „íŠ¸ë“¤ ì‚¬ìš©
            self.agents = {
                "planner": self._create_simple_planner(),
                "date_processor": self._create_simple_date_processor(),
                "external_search": self._create_simple_external_search()
            }
            logger.info("ğŸ“ Mock ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì˜¤ë¥˜ë¡œ ì¸í•œ Fallback)")
    
    def execute_workflow(self, 
                        query: str, 
                        user_context: Dict = None,
                        execution_options: Dict = None) -> Dict:
        """
        ë©”ì¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í•¨ìˆ˜
        """
        execution_id = f"exec_{int(time.time() * 1000)}"
        start_time = time.time()
        
        execution_context = {
            "execution_id": execution_id,
            "query": query,
            "user_context": user_context or {},
            "options": execution_options or {},
            "start_time": start_time,
            "steps": [],
            "metrics": {},
            "final_result": None
        }
        
        try:
            logger.info(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘: {execution_id}")
            
            # Step 1: Planning (í•„ìˆ˜)
            logger.info("ğŸ“‹ Planning ë‹¨ê³„ ì‹œì‘")
            planning_result = self._execute_planning_step(execution_context)
            logger.info(f"ğŸ“‹ Planning ë‹¨ê³„ ì™„ë£Œ: {planning_result.get('success')}")
            if not planning_result["success"]:
                return self._handle_execution_failure(execution_context, "planning_failed")
            
            # Step 2: ì¡°ê±´ë¶€ ì‹¤í–‰ ë‹¨ê³„ë“¤
            execution_plan = planning_result["data"]["execution_plan"]["actions"]
            logger.info(f"ğŸ”„ ì‹¤í–‰í•  ë‹¨ê³„ ìˆ˜: {len(execution_plan)}")
            
            for i, step_config in enumerate(execution_plan, 1):
                logger.info(f"âš™ï¸ ë‹¨ê³„ {i}/{len(execution_plan)} ì‹¤í–‰: {step_config.get('type')}")
                step_result = self._execute_conditional_step(execution_context, step_config)
                logger.info(f"âœ… ë‹¨ê³„ {i} ì™„ë£Œ: {step_result.get('success')}")
                execution_context["steps"].append(step_result)
                
                # ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§
                if not step_result["success"] and step_config.get("critical", False):
                    retry_result = self._handle_step_retry(execution_context, step_config)
                    if not retry_result["success"]:
                        return self._handle_execution_failure(execution_context, f"{step_config['type']}_failed")
            
            # Step 3: ìµœì¢… ê²°ê³¼ í•©ì„±
            final_result = self._synthesize_final_result(execution_context)
            
            # Step 4: í’ˆì§ˆ ê²€ì¦
            quality_check = self._perform_quality_check(final_result)
            
            # í’ˆì§ˆì´ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´ ì¬ì‹œë„
            if quality_check["score"] < self.thresholds[ThresholdType.QUALITY]:
                logger.info(f"í’ˆì§ˆ ì ìˆ˜ ë¶€ì¡± ({quality_check['score']:.2f}), ì¬ì‹œë„ ìˆ˜í–‰")
                retry_result = self._retry_with_enhanced_context(execution_context)
                if retry_result["success"]:
                    final_result = retry_result["data"]
            
            # ì„±ê³µ ì²˜ë¦¬
            execution_time = time.time() - start_time
            self._record_success_metrics(execution_context, execution_time)
            
            return {
                "success": True,
                "execution_id": execution_id,
                "result": final_result,
                "thinking_process": self._extract_thinking_process(execution_context),  # ğŸ§  ì‚¬ê³  ê³¼ì • ì¶”ê°€
                "metadata": {
                    "execution_time": execution_time,
                    "steps_executed": len(execution_context["steps"]),
                    "quality_score": quality_check["score"],
                    "external_search_used": any(step.get("step_type") == "external_search" for step in execution_context["steps"]),
                    "retries_performed": sum(1 for step in execution_context["steps"] if step.get("retries", 0) > 0)
                }
            }
            
        except Exception as e:
            logger.error(f"ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._handle_execution_failure(execution_context, f"unexpected_error: {str(e)}")

    def _extract_thinking_process(self, execution_context: Dict) -> List[Dict]:
        """
        ì‹¤ì œ Enhanced Agent Systemì˜ ì‚¬ê³  ê³¼ì •ì„ ìƒì„¸íˆ ì¶”ì¶œ
        """
        thinking_steps = []
        
        try:
            # Planning ë‹¨ê³„ - ì‹¤ì œ ì—ì´ì „íŠ¸ ì •ë³´ í¬í•¨
            planning_result = execution_context.get("planning_result", {})
            date_strategy = execution_context.get("date_strategy", {})
            
            # 1. ReAct Planning ë‹¨ê³„
            thinking_steps.append({
                "step_name": "ğŸ§  ReAct Planning (ì‚¬ê³ +í–‰ë™)",
                "description": f"'{execution_context['query'][:50]}...' ì§ˆë¬¸ì„ ReAct ë°©ì‹ìœ¼ë¡œ ë¶„ì„í•˜ê³  Chain-of-Thought ì¶”ë¡ ì„ í†µí•´ ì‹¤í–‰ ê³„íšì„ ìˆ˜ë¦½í–ˆìŠµë‹ˆë‹¤.",
                "result": f"ê³„íš ìˆ˜ë¦½ ì™„ë£Œ - {len(execution_context.get('steps', []))}ë‹¨ê³„ ì‹¤í–‰ ì˜ˆì •",
                "execution_time": 0.5
            })
            
            # 2. ë‚ ì§œ ì§€ëŠ¥í˜• ë¶„ì„ (ì‹¤ì œ ê²°ê³¼ ë°˜ì˜)
            if date_strategy.get("has_date_expression"):
                date_desc = f"'{date_strategy.get('time_expression', '')}' í‘œí˜„ì„ ê°ì§€í•˜ì—¬ {date_strategy.get('date_range', {}).get('start', 'N/A')}ë¶€í„° ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."
                date_result = f"íŠ¹ì • ê¸°ê°„ ê²€ìƒ‰ ({date_strategy.get('primary_strategy', 'unknown')})"
            else:
                date_desc = "ë‚ ì§œ í‘œí˜„ì´ ì—†ì–´ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ë„ë¡ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."
                date_result = "ìµœì‹ ìˆœ ìš°ì„  ê²€ìƒ‰"
                
            thinking_steps.append({
                "step_name": "ğŸ“… ë‚ ì§œ ì§€ëŠ¥í˜• ì²˜ë¦¬",
                "description": date_desc,
                "result": date_result,
                "execution_time": 0.3
            })
            
            # 3. ê° ì‹¤í–‰ ë‹¨ê³„ë³„ ìƒì„¸ ì‚¬ê³  ê³¼ì •
            for i, step in enumerate(execution_context.get("steps", []), 3):
                step_type = step.get("type", "unknown")
                step_success = step.get("success", False)
                step_data = step.get("data", {})
                step_time = step.get("execution_time", 0)
                
                # ì‹¤ì œ ì—ì´ì „íŠ¸ ê²°ê³¼ ê¸°ë°˜ ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ëª…
                if step_type == "internal_search":
                    sources_count = len(step_data.get("sources", []))
                    coverage_score = step_data.get("coverage_score", 0)
                    
                    thinking_steps.append({
                        "step_name": "ğŸ“š ë‚´ë¶€ ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰",
                        "description": f"AWS Bedrock Knowledge Baseì—ì„œ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤. ì»¤ë²„ë¦¬ì§€: {coverage_score:.1f}/5.0",
                        "result": f"ì„±ê³µ ({sources_count}ê°œ ì†ŒìŠ¤ ë°œê²¬)" if step_success else "ì •ë³´ ë¶€ì¡±",
                        "execution_time": step_time
                    })
                    
                elif step_type == "external_search":
                    confidence = step_data.get("confidence", 0)
                    sources_count = len(step_data.get("sources", []))
                    
                    thinking_steps.append({
                        "step_name": "ğŸŒ Perplexity ì™¸ë¶€ ì›¹ ê²€ìƒ‰",
                        "description": f"ë‚´ë¶€ ì§€ì‹ì´ ë¶€ì¡±í•˜ì—¬ Perplexity APIë¡œ ìµœì‹  ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤. ì‹ ë¢°ë„: {confidence:.1f}/5.0",
                        "result": f"ì„±ê³µ ({sources_count}ê°œ ì™¸ë¶€ ì†ŒìŠ¤ ë°œê²¬)" if step_success else "ê²€ìƒ‰ ì‹¤íŒ¨",
                        "execution_time": step_time
                    })
                    
                elif step_type == "query_rewrite":
                    original_clarity = step_data.get("original_clarity", 0)
                    rewritten_queries = step_data.get("rewritten_queries", [])
                    
                    thinking_steps.append({
                        "step_name": "âœï¸ ì§ˆë¬¸ ì¬êµ¬ì„± (Few-shot)",
                        "description": f"ì›ë³¸ ì§ˆë¬¸ì˜ ëª…í™•ë„({original_clarity:.1f}/5.0)ê°€ ë‚®ì•„ Few-shot ê¸°ë²•ìœ¼ë¡œ ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ì¬êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.",
                        "result": f"ì„±ê³µ ({len(rewritten_queries)}ê°œ ëŒ€ì•ˆ ìƒì„±)" if step_success else "ì¬êµ¬ì„± ì‹¤íŒ¨",
                        "execution_time": step_time
                    })
                    
                elif step_type == "answer_synthesis":
                    quality_score = step_data.get("quality_score", 0)
                    word_count = step_data.get("word_count", 0)
                    
                    thinking_steps.append({
                        "step_name": "ğŸ“ Few-shot ë‹µë³€ ìƒì„±",
                        "description": f"ê²€ìƒ‰ ê²°ê³¼ë¥¼ Few-shot í”„ë¡¬í”„íŒ… ê¸°ë²•ìœ¼ë¡œ MZì„¸ëŒ€ ì¹œí™”ì ì¸ ê³ í’ˆì§ˆ ë‹µë³€ìœ¼ë¡œ í•©ì„±í–ˆìŠµë‹ˆë‹¤.",
                        "result": f"í’ˆì§ˆ {quality_score:.1f}/5.0 ({word_count}ì)" if step_success else "ìƒì„± ì‹¤íŒ¨",
                        "execution_time": step_time
                    })
                    
                elif step_type == "quality_check":
                    final_score = step_data.get("final_score", 0)
                    threshold_met = step_data.get("threshold_met", False)
                    
                    thinking_steps.append({
                        "step_name": "âœ… í’ˆì§ˆ ì„ê³„ê°’ ê²€ì¦",
                        "description": f"ìƒì„±ëœ ë‹µë³€ì˜ í’ˆì§ˆì„ ì„ê³„ê°’({self.thresholds.get(ThresholdType.QUALITY, 3.0)})ê³¼ ë¹„êµí•˜ì—¬ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.",
                        "result": f"{'í†µê³¼' if threshold_met else 'ì¬ì‹œë„ í•„ìš”'} (ì ìˆ˜: {final_score:.1f})" if step_success else "ê²€ì¦ ì‹¤íŒ¨",
                        "execution_time": step_time
                    })
                    
                else:
                    # ê¸°ë³¸ ë‹¨ê³„ ì²˜ë¦¬ - ì‹¤ì œ ì‹¤í–‰ë˜ëŠ” ëª¨ë“  ë‹¨ê³„ ë§¤í•‘
                    step_names = {
                        "analysis": "ğŸ” AnalyzerAgent ë¶„ì„",
                        "query_rewrite": "âœï¸ ì§ˆë¬¸ ì¬êµ¬ì„± (Few-shot)",
                        "date_analysis": "ğŸ“… DateProcessor ì²˜ë¦¬",
                        "latest_first_search": "ğŸ†• ìµœì‹ ìˆœ ìš°ì„  ê²€ìƒ‰",
                        "date_filtered_search": "ğŸ“† ë‚ ì§œ í•„í„° ê²€ìƒ‰",
                        "internal_search": "ğŸ“š ë‚´ë¶€ ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰",
                        "external_search": "ğŸŒ Perplexity ì™¸ë¶€ ê²€ìƒ‰",
                        "answer_synthesis": "ğŸ“ Few-shot ë‹µë³€ ìƒì„±",
                        "quality_check": "âœ… í’ˆì§ˆ ì„ê³„ê°’ ê²€ì¦"
                    }
                    
                    step_name = step_names.get(step_type, f"âš™ï¸ {step_type} ì²˜ë¦¬")
                    
                    # ë‹¨ê³„ë³„ ìƒì„¸ ì„¤ëª… ìƒì„±
                    if step_type == "query_rewrite":
                        description = "ì›ë³¸ ì§ˆë¬¸ì„ Few-shot ê¸°ë²•ìœ¼ë¡œ ë” êµ¬ì²´ì ì´ê³  ê²€ìƒ‰í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì¬êµ¬ì„±í–ˆìŠµë‹ˆë‹¤."
                    elif step_type == "latest_first_search":
                        description = "ë‚ ì§œ í‘œí˜„ì´ ì—†ì–´ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê²€ìƒ‰í•˜ë„ë¡ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."
                    elif step_type == "internal_search":
                        description = "AWS Bedrock Knowledge Baseì—ì„œ ê´€ë ¨ ë‰´ìŠ¤ì™€ ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                    elif step_type == "date_filtered_search":
                        description = "íŠ¹ì • ë‚ ì§œ ë²”ìœ„ë¡œ í•„í„°ë§í•˜ì—¬ í•´ë‹¹ ê¸°ê°„ì˜ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                    else:
                        description = f"{step_type} ë‹¨ê³„ë¥¼ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤."
                    
                    thinking_steps.append({
                        "step_name": step_name,
                        "description": description,
                        "result": "ì„±ê³µ" if step_success else "ì‹¤íŒ¨",
                        "execution_time": step_time
                    })
            
            return thinking_steps[:8]  # ìµœëŒ€ 8ë‹¨ê³„ê¹Œì§€ í‘œì‹œ
            
        except Exception as e:
            logger.error(f"ì‚¬ê³  ê³¼ì • ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            # Fallback: ê¸°ë³¸ ì‚¬ê³  ê³¼ì •
            return [
                {
                    "step_name": "ğŸ§  AI ì¢…í•© ì‚¬ê³  ê³¼ì •",
                    "description": "Enhanced Agent Systemì´ ReAct + CoT ë°©ì‹ìœ¼ë¡œ ë‹¨ê³„ë³„ ì‚¬ê³ í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.",
                    "result": "ì™„ë£Œ",
                    "execution_time": 2.0
                },
                {
                    "step_name": "ğŸ“š ì§€ì‹ í†µí•© ê²€ìƒ‰",
                    "description": "ë‚´ë¶€ Knowledge Baseì™€ í•„ìš”ì‹œ ì™¸ë¶€ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.",
                    "result": "ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ",
                    "execution_time": 1.5
                }
            ]
    
    def _execute_planning_step(self, execution_context: Dict) -> Dict:
        """Planning ë‹¨ê³„ ì‹¤í–‰"""
        try:
            query = execution_context["query"]
            user_context = execution_context["user_context"]
            
            # Planning Agent í˜¸ì¶œ
            planning_result = self.agents["planner"].plan_execution(query, user_context)
            
            # ë‚ ì§œ ì²˜ë¦¬ ì¶”ê°€
            date_analysis = self.agents["date_processor"].analyze_query_temporal_expressions(query)
            
            # ê²°ê³¼ í†µí•©
            enhanced_context = {
                **planning_result,
                "date_analysis": date_analysis,
                "temporal_strategy": date_analysis.get("primary_strategy", "latest_first")
            }
            
            # ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            execution_context["planning_result"] = enhanced_context
            execution_context["date_strategy"] = date_analysis
            
            return {
                "success": True,
                "step_type": "planning",
                "data": enhanced_context,
                "execution_time": 0.5,  # ì˜ˆìƒ ì‹œê°„
                "thresholds_checked": []
            }
            
        except Exception as e:
            logger.error(f"Planning ë‹¨ê³„ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "step_type": "planning",
                "error": str(e),
                "execution_time": 0.0
            }
    
    def _execute_conditional_step(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ì¡°ê±´ë¶€ ë‹¨ê³„ ì‹¤í–‰"""
        step_type = step_config["type"]
        step_start_time = time.time()
        
        try:
            # ì¡°ê±´ í™•ì¸
            should_execute = self._check_execution_condition(execution_context, step_config)
            
            if not should_execute:
                return {
                    "success": True,
                    "step_type": step_type,
                    "status": ExecutionStatus.SKIPPED.value,
                    "reason": "condition_not_met",
                    "execution_time": 0.0
                }
            
            # ë‹¨ê³„ë³„ ì‹¤í–‰
            if step_type == "query_rewrite":
                result = self._execute_query_rewrite(execution_context, step_config)
            elif step_type == "internal_search":
                result = self._execute_internal_search(execution_context, step_config)
            elif step_type == "external_search":
                result = self._execute_external_search(execution_context, step_config)
            elif step_type == "date_filtered_search":
                result = self._execute_date_filtered_search(execution_context, step_config)
            elif step_type == "latest_first_search":
                result = self._execute_latest_first_search(execution_context, step_config)
            elif step_type == "answer_synthesis":
                result = self._execute_answer_synthesis(execution_context, step_config)
            elif step_type == "quality_check":
                result = self._execute_quality_check(execution_context, step_config)
            else:
                result = self._execute_generic_step(execution_context, step_config)
            
            execution_time = time.time() - step_start_time
            result["execution_time"] = execution_time
            
            return result
            
        except Exception as e:
            logger.error(f"{step_type} ë‹¨ê³„ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "step_type": step_type,
                "error": str(e),
                "execution_time": time.time() - step_start_time
            }
    
    def _check_execution_condition(self, execution_context: Dict, step_config: Dict) -> bool:
        """ì‹¤í–‰ ì¡°ê±´ í™•ì¸"""
        step_type = step_config["type"]
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ë‹¨ê³„ëŠ” ì‹¤í–‰
        if "condition" not in step_config:
            return True
        
        condition = step_config["condition"]
        
        # ì¡°ê±´ë³„ í™•ì¸
        if condition == "if_internal_insufficient":
            # ë‚´ë¶€ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•œ ê²½ìš°ë§Œ ì‹¤í–‰
            internal_coverage = execution_context.get("internal_coverage", 0.0)
            return internal_coverage < self.thresholds[ThresholdType.COVERAGE]
        
        elif condition == "if_quality_low":
            # í’ˆì§ˆì´ ë‚®ì€ ê²½ìš°ë§Œ ì‹¤í–‰
            current_quality = execution_context.get("current_quality", 1.0)
            return current_quality < self.thresholds[ThresholdType.QUALITY]
        
        elif condition == "if_clarity_low":
            # ëª…í™•ì„±ì´ ë‚®ì€ ê²½ìš°ë§Œ ì‹¤í–‰
            clarity_score = execution_context.get("clarity_score", 1.0)
            return clarity_score < self.thresholds[ThresholdType.CLARITY]
        
        elif condition == "if_freshness_required":
            # ì‹ ì„ ë„ê°€ ë†’ê²Œ ìš”êµ¬ë˜ëŠ” ê²½ìš°ë§Œ ì‹¤í–‰
            freshness_priority = execution_context.get("freshness_priority", 0.0)
            return freshness_priority > self.thresholds[ThresholdType.FRESHNESS]
        
        # ì•Œ ìˆ˜ ì—†ëŠ” ì¡°ê±´ì€ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¡°ê±´: {condition}")
        return False
    
    def _execute_external_search(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ì™¸ë¶€ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            query = execution_context["query"]
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            search_context = {
                "internal_coverage": execution_context.get("internal_coverage", 0.0),
                "freshness_priority": execution_context.get("freshness_priority", 0.0),
                "complexity_level": execution_context.get("complexity_level", "simple"),
                "date_strategy": execution_context.get("date_strategy", {})
            }
            
            # Perplexity ê²€ìƒ‰ ì‹¤í–‰
            search_result = self.agents["external_search"].search_external_knowledge(
                query, search_context
            )
            
            # ê²°ê³¼ë¥¼ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ì— ì €ì¥
            execution_context["external_search_result"] = search_result
            execution_context["external_coverage"] = search_result.confidence
            
            return {
                "success": True,
                "step_type": "external_search",
                "data": search_result,
                "status": ExecutionStatus.COMPLETED.value,
                "confidence": getattr(search_result, 'confidence', 0.0),
                "sources_found": len(getattr(search_result, 'sources', []) or getattr(search_result, 'recommended_sources', []))
            }
            
        except Exception as e:
            logger.error(f"ì™¸ë¶€ ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "step_type": "external_search",
                "error": str(e),
                "status": ExecutionStatus.FAILED.value
            }
    
    def _execute_internal_search(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ë‚´ë¶€ ê²€ìƒ‰ ì‹¤í–‰ (Knowledge Base)"""
        try:
            query = execution_context["query"]
            logger.info(f"ğŸ” Knowledge Base ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            # ì‹¤ì œ Knowledge Base ê²€ìƒ‰ ì‹¤í–‰
            internal_result = self._search_knowledge_base(query)
            logger.info(f"ğŸ“š Knowledge Base ê²€ìƒ‰ ì™„ë£Œ: {len(internal_result.get('sources', []))}ê°œ ì†ŒìŠ¤ ë°œê²¬")
            
            # ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            execution_context["internal_search_result"] = internal_result
            execution_context["internal_coverage"] = internal_result["coverage_score"]
            
            return {
                "success": True,
                "step_type": "internal_search",
                "data": internal_result,
                "status": ExecutionStatus.COMPLETED.value,
                "coverage": internal_result["coverage_score"]
            }
            
        except Exception as e:
            logger.error(f"ë‚´ë¶€ ê²€ìƒ‰ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "step_type": "internal_search",
                "error": str(e),
                "status": ExecutionStatus.FAILED.value
            }
    
    def _search_knowledge_base(self, query: str) -> Dict:
        """Knowledge Base ê²€ìƒ‰ (stream.pyì™€ ë™ì¼í•œ ë¡œì§)"""
        try:
            import boto3
            import os
            import re
            
            bedrock_agent_client = boto3.client("bedrock-agent-runtime")
            KNOWLEDGE_BASE_ID = os.environ.get('KNOWLEDGE_BASE_ID', 'PGQV3JXPET')
            
            response = bedrock_agent_client.retrieve(
                knowledgeBaseId=KNOWLEDGE_BASE_ID,
                retrievalQuery={'text': query},
                retrievalConfiguration={
                    'vectorSearchConfiguration': {
                        'numberOfResults': 5,
                        'overrideSearchType': 'HYBRID'
                    }
                }
            )
            
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¡œ ë³€í™˜
            contexts = []
            sources = []
            seen = set()
            skipped_count = 0
            
            for idx, result in enumerate(response.get('retrievalResults', [])[:5], 1):
                text = result.get('content', {}).get('text', '')
                
                if not text.strip():
                    continue
                
                # Knowledge Baseì—ì„œ ë°˜í™˜ëœ ë°ì´í„° íŒŒì‹±
                articles = []
                lines = text.splitlines()
                
                if lines:
                    title_line = lines[0].strip()
                    if title_line.startswith('"') and title_line.endswith('"'):
                        title_line = title_line[1:-1]
                    
                    current = {"title": title_line}
                    
                    for line in lines[1:]:
                        line = line.strip()
                        if line.startswith("**") and ":**" in line:
                            try:
                                key_end = line.find(":**")
                                if key_end > 2:
                                    key = line[2:key_end].strip()
                                    value = line[key_end + 3:].strip()
                                    current[key] = value
                            except:
                                pass
                        elif line.startswith("**ë‚´ìš©:**"):
                            break
                    
                    if current.get("title"):
                        articles.append(current)
                
                # ê¸°ì‚¬ë³„ ì²˜ë¦¬
                for article in articles:
                    url = article.get("URL", "")
                    title = article.get("title", "")
                    published_date = article.get("ë°œí–‰ì¼", "")
                    
                    if not title:
                        skipped_count += 1
                        continue
                    
                    if url and url in seen:
                        skipped_count += 1
                        continue
                    if url:
                        seen.add(url)
                    
                    # ë‚ ì§œ í¬ë§·íŒ…
                    formatted_date = ""
                    if published_date and "T" in published_date:
                        formatted_date = published_date.split("T")[0]
                    elif published_date:
                        formatted_date = published_date
                    
                    source_info = {
                        'id': len(sources) + 1,
                        'title': title,
                        'date': formatted_date,
                        'url': url if url else f"#article-{len(sources) + 1}"
                    }
                    sources.append(source_info)
                    
                    context_text = f"ì œëª©: {title}"
                    if formatted_date:
                        context_text += f"\në°œí–‰ì¼: {formatted_date}"
                    if url:
                        context_text += f"\nURL: {url}"
                    contexts.append(f"[{len(sources)}] {context_text}")
            
            if contexts:
                knowledge_context = "\\n\\n=== ì„œìš¸ê²½ì œì‹ ë¬¸ ê´€ë ¨ ë‰´ìŠ¤ ===\\n" + "\\n\\n".join(contexts[:3])
                coverage_score = min(len(sources) / 3.0, 1.0)  # 3ê°œ ì´ìƒì´ë©´ ì™„ì „í•œ ì»¤ë²„ë¦¬ì§€
                
                return {
                    'content': knowledge_context,
                    'sources': sources,
                    'coverage_score': coverage_score
                }
            else:
                return {
                    'content': "",
                    'sources': [],
                    'coverage_score': 0.0
                }
                
        except Exception as e:
            logger.error(f"Knowledge Base ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
            return {
                'content': "",
                'sources': [],
                'coverage_score': 0.0
            }
    
    def _execute_date_filtered_search(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ë‚ ì§œ í•„í„°ë§ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            date_range = step_config.get("date_range", {})
            query = execution_context["query"]
            
            # ë‚ ì§œ ê¸°ë°˜ ê²€ìƒ‰ ë¡œì§
            search_result = {
                "content": f"ë‚ ì§œ í•„í„°ë§ ê²€ìƒ‰ ê²°ê³¼: {query}",
                "date_range": date_range,
                "filtered_count": 15  # ì˜ˆì‹œ
            }
            
            execution_context["date_filtered_result"] = search_result
            
            return {
                "success": True,
                "step_type": "date_filtered_search",
                "data": search_result,
                "status": ExecutionStatus.COMPLETED.value,
                "filtered_articles": search_result["filtered_count"]
            }
            
        except Exception as e:
            return {
                "success": False,
                "step_type": "date_filtered_search",
                "error": str(e),
                "status": ExecutionStatus.FAILED.value
            }
    
    def _execute_latest_first_search(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ìµœì‹ ìˆœ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            query = execution_context["query"]
            
            # ìµœì‹ ìˆœ ê²€ìƒ‰ ë¡œì§
            search_result = {
                "content": f"ìµœì‹ ìˆœ ê²€ìƒ‰ ê²°ê³¼: {query}",
                "sort_order": "latest_first",
                "latest_articles": 20  # ì˜ˆì‹œ
            }
            
            execution_context["latest_first_result"] = search_result
            
            return {
                "success": True,
                "step_type": "latest_first_search", 
                "data": search_result,
                "status": ExecutionStatus.COMPLETED.value,
                "articles_found": search_result["latest_articles"]
            }
            
        except Exception as e:
            return {
                "success": False,
                "step_type": "latest_first_search",
                "error": str(e),
                "status": ExecutionStatus.FAILED.value
            }
    
    def _execute_query_rewrite(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ì§ˆë¬¸ ì¬ì‘ì„± ì‹¤í–‰"""
        try:
            original_query = execution_context["query"]
            
            # ì§ˆë¬¸ ì¬ì‘ì„± ë¡œì§ (Mock)
            rewritten_query = f"{original_query} (ì¬ì‘ì„±ë¨)"
            
            execution_context["rewritten_query"] = rewritten_query
            execution_context["clarity_score"] = 0.9  # ì¬ì‘ì„± í›„ ë†’ì€ ì ìˆ˜
            
            return {
                "success": True,
                "step_type": "query_rewrite",
                "data": {"rewritten_query": rewritten_query},
                "status": ExecutionStatus.COMPLETED.value,
                "clarity_improvement": 0.3
            }
            
        except Exception as e:
            return {
                "success": False,
                "step_type": "query_rewrite",
                "error": str(e),
                "status": ExecutionStatus.FAILED.value
            }
    
    def _execute_answer_synthesis(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ë‹µë³€ í•©ì„± ì‹¤í–‰"""
        try:
            # ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ ìƒì„±
            internal_result = execution_context.get("internal_search_result", {})
            external_result = execution_context.get("external_search_result")
            query = execution_context.get("query", "")
            
            # Knowledge Base ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±
            if internal_result.get("sources"):
                sources = internal_result.get("sources", [])
                content = internal_result.get("content", "")
                
                # ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± (ì‹¤ì œë¡œëŠ” LLMì„ ì‚¬ìš©í•´ì•¼ í•¨)
                answer_content = f"ì„œìš¸ê²½ì œì‹ ë¬¸ì˜ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n\n"
                
                # ê° ì†ŒìŠ¤ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª… ì¶”ê°€
                for i, source in enumerate(sources[:3], 1):
                    answer_content += f"[{i}] {source['title']}"
                    if source.get('date'):
                        answer_content += f" ({source['date']})"
                    answer_content += "\n"
                
                answer_content += f"\nìœ„ì˜ ê¸°ì‚¬ë“¤ì´ '{query}' ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì„œìš¸ê²½ì œì‹ ë¬¸ì˜ ë³´ë„ ë‚´ìš©ì…ë‹ˆë‹¤."
                
                synthesized_answer = {
                    "content": answer_content,
                    "sources": sources,
                    "confidence": 0.8
                }
            else:
                # Knowledge Baseì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
                synthesized_answer = {
                    "content": f"'{query}'ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì„œìš¸ê²½ì œì‹ ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤.",
                    "sources": [],
                    "confidence": 0.3
                }
            
            # ì™¸ë¶€ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€ (í˜„ì¬ëŠ” ë¹„í™œì„±í™”)
            if external_result and hasattr(external_result, 'sources') and external_result.sources:
                synthesized_answer["sources"].extend(external_result.sources)
            
            execution_context["synthesized_answer"] = synthesized_answer
            
            return {
                "success": True,
                "step_type": "answer_synthesis",
                "data": synthesized_answer,
                "status": ExecutionStatus.COMPLETED.value,
                "sources_count": len(synthesized_answer["sources"])
            }
            
        except Exception as e:
            logger.error(f"ë‹µë³€ í•©ì„± ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "step_type": "answer_synthesis",
                "error": str(e),
                "status": ExecutionStatus.FAILED.value
            }
    
    def _execute_quality_check(self, execution_context: Dict, step_config: Dict) -> Dict:
        """í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰"""
        try:
            answer = execution_context.get("synthesized_answer", {})
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_quality_score(answer, execution_context)
            
            execution_context["current_quality"] = quality_score
            
            return {
                "success": True,
                "step_type": "quality_check",
                "data": {"quality_score": quality_score},
                "status": ExecutionStatus.COMPLETED.value,
                "quality_score": quality_score,
                "meets_threshold": quality_score >= self.thresholds[ThresholdType.QUALITY]
            }
            
        except Exception as e:
            return {
                "success": False,
                "step_type": "quality_check",
                "error": str(e),
                "status": ExecutionStatus.FAILED.value
            }
    
    def _execute_generic_step(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ì¼ë°˜ì ì¸ ë‹¨ê³„ ì‹¤í–‰"""
        return {
            "success": True,
            "step_type": step_config["type"],
            "data": {},
            "status": ExecutionStatus.COMPLETED.value,
            "note": "generic_execution"
        }
    
    def _calculate_quality_score(self, answer: Dict, context: Dict) -> float:
        """ë‹µë³€ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ë‚´ìš© ê¸¸ì´ í‰ê°€
        content = answer.get("content", "")
        if len(content) > 100:
            score += 0.1
        if len(content) > 300:
            score += 0.1
        
        # ì¶œì²˜ ê°œìˆ˜ í‰ê°€
        sources = answer.get("sources", [])
        if len(sources) >= 2:
            score += 0.15
        if len(sources) >= 4:
            score += 0.1
        
        # ì‹ ë¢°ë„ í‰ê°€
        confidence = answer.get("confidence", 0.5)
        score += confidence * 0.2
        
        return min(score, 1.0)
    
    def _synthesize_final_result(self, execution_context: Dict) -> Dict:
        """ìµœì¢… ê²°ê³¼ í•©ì„±"""
        synthesized_answer = execution_context.get("synthesized_answer", {})
        
        return {
            "answer": synthesized_answer.get("content", "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "sources": synthesized_answer.get("sources", []),
            "metadata": {
                "execution_id": execution_context["execution_id"],
                "steps_executed": len(execution_context["steps"]),
                "date_strategy": execution_context.get("date_strategy", {}),
                "quality_score": execution_context.get("current_quality", 0.0)
            }
        }
    
    def _perform_quality_check(self, final_result: Dict) -> Dict:
        """ìµœì¢… í’ˆì§ˆ ê²€ì¦"""
        answer_content = final_result.get("answer", "")
        sources = final_result.get("sources", [])
        
        quality_score = 0.5
        
        # ë‹µë³€ ë‚´ìš© í‰ê°€
        if len(answer_content) > 50:
            quality_score += 0.2
        if "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in answer_content:
            quality_score += 0.2
        
        # ì¶œì²˜ í‰ê°€
        if len(sources) > 0:
            quality_score += 0.1
        
        return {
            "score": quality_score,
            "meets_threshold": quality_score >= self.thresholds[ThresholdType.QUALITY],
            "details": {
                "content_quality": len(answer_content) > 50,
                "has_sources": len(sources) > 0,
                "non_error_response": "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in answer_content
            }
        }
    
    def _handle_step_retry(self, execution_context: Dict, step_config: Dict) -> Dict:
        """ë‹¨ê³„ ì¬ì‹œë„ ì²˜ë¦¬"""
        max_retries = self.retry_config["max_retries"]
        current_retries = step_config.get("retries", 0)
        
        if current_retries >= max_retries:
            return {"success": False, "reason": "max_retries_exceeded"}
        
        # ì¬ì‹œë„ ì§€ì—°
        delay = self.retry_config["retry_delay"]
        if self.retry_config["exponential_backoff"]:
            delay *= (2 ** current_retries)
        
        time.sleep(delay)
        
        # ì¬ì‹œë„ ì‹¤í–‰
        step_config["retries"] = current_retries + 1
        retry_result = self._execute_conditional_step(execution_context, step_config)
        
        return retry_result
    
    def _retry_with_enhanced_context(self, execution_context: Dict) -> Dict:
        """í–¥ìƒëœ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¬ì‹œë„"""
        try:
            # ì›ë˜ ì§ˆë¬¸ì„ ë” êµ¬ì²´í™”
            original_query = execution_context["query"]
            enhanced_query = f"{original_query} (ë” ìì„¸í•œ ì •ë³´ í•„ìš”)"
            
            # ìƒˆë¡œìš´ ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            retry_context = execution_context.copy()
            retry_context["query"] = enhanced_query
            retry_context["retry_attempt"] = True
            
            # ì™¸ë¶€ ê²€ìƒ‰ ê°•ì œ ì‹¤í–‰
            search_context = {
                "internal_coverage": 0.0,  # ë‚®ê²Œ ì„¤ì •í•˜ì—¬ ì™¸ë¶€ ê²€ìƒ‰ ìœ ë„
                "freshness_priority": 0.9,
                "complexity_level": "complex"
            }
            
            external_result = self.agents["external_search"].search_external_knowledge(
                enhanced_query, search_context, force_search=True
            )
            
            if external_result.confidence > 0.5:
                return {
                    "success": True,
                    "data": {
                        "answer": external_result.content,
                        "sources": external_result.sources,
                        "metadata": {"retry_enhanced": True}
                    }
                }
            
            return {"success": False, "reason": "retry_also_failed"}
            
        except Exception as e:
            logger.error(f"ì¬ì‹œë„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {"success": False, "reason": f"retry_error: {str(e)}"}
    
    def _handle_execution_failure(self, execution_context: Dict, reason: str) -> Dict:
        """ì‹¤í–‰ ì‹¤íŒ¨ ì²˜ë¦¬"""
        execution_time = time.time() - execution_context["start_time"]
        
        self._record_failure_metrics(execution_context, execution_time, reason)
        
        return {
            "success": False,
            "execution_id": execution_context["execution_id"],
            "error": reason,
            "metadata": {
                "execution_time": execution_time,
                "steps_completed": len(execution_context["steps"]),
                "failure_point": reason
            }
        }
    
    def _record_success_metrics(self, execution_context: Dict, execution_time: float):
        """ì„±ê³µ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.performance_metrics["total_executions"] += 1
        self.performance_metrics["successful_executions"] += 1
        self.performance_metrics["avg_execution_time"] = (
            (self.performance_metrics["avg_execution_time"] * (self.performance_metrics["total_executions"] - 1) + execution_time) /
            self.performance_metrics["total_executions"]
        )
        
        # ì™¸ë¶€ ê²€ìƒ‰ ì‚¬ìš©ë¥  ê³„ì‚°
        used_external = any(step.get("step_type") == "external_search" for step in execution_context["steps"])
        if used_external:
            self.performance_metrics["external_search_rate"] = (
                (self.performance_metrics["external_search_rate"] * (self.performance_metrics["total_executions"] - 1) + 1) /
                self.performance_metrics["total_executions"]
            )
    
    def _record_failure_metrics(self, execution_context: Dict, execution_time: float, reason: str):
        """ì‹¤íŒ¨ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        self.performance_metrics["total_executions"] += 1
        self.performance_metrics["failed_executions"] += 1
        
        logger.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {execution_context['execution_id']}, ì´ìœ : {reason}")
    
    def _create_simple_planner(self):
        """ê°„ë‹¨í•œ ê³„íš ì—ì´ì „íŠ¸"""
        class SimplePlanner:
            def plan_execution(self, query: str, user_context: Dict = None):
                # ì‹¤ì œ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
                plan = {
                    "execution_plan": {
                        "actions": [
                            {"type": "internal_search", "critical": True},
                            {"type": "answer_synthesis", "critical": True}
                        ]
                    },
                    "clarity_score": 0.8,
                    "complexity_level": "simple"
                }
                
                # íŠ¹ì • í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì™¸ë¶€ ê²€ìƒ‰ë„ í¬í•¨
                if any(keyword in query.lower() for keyword in ["ìµœì‹ ", "í˜„ì¬", "ì§€ê¸ˆ", "ì˜¤ëŠ˜"]):
                    plan["execution_plan"]["actions"].insert(1, {
                        "type": "external_search", 
                        "condition": "if_internal_insufficient",
                        "critical": False
                    })
                    plan["freshness_priority"] = 0.8
                
                return plan
        
        return SimplePlanner()
    
    def _create_simple_date_processor(self):
        """ê°„ë‹¨í•œ ë‚ ì§œ ì²˜ë¦¬ ì—ì´ì „íŠ¸"""
        class SimpleDateProcessor:
            def analyze_query_temporal_expressions(self, query: str):
                # ê°„ë‹¨í•œ ë‚ ì§œ í‘œí˜„ ë¶„ì„
                import re
                
                date_keywords = ["ì–´ì œ", "ì˜¤ëŠ˜", "ë‚´ì¼", "ìµœê·¼", "ìµœì‹ ", "í˜„ì¬", "ì§€ê¸ˆ"]
                has_date = any(keyword in query for keyword in date_keywords)
                
                return {
                    "has_date_expression": has_date,
                    "time_expression": "ìµœì‹ " if has_date else "",
                    "primary_strategy": "latest_first" if has_date else "relevance_first",
                    "temporal_priority": 0.8 if has_date else 0.3
                }
        
        return SimpleDateProcessor()
    
    def _create_simple_external_search(self):
        """ê°„ë‹¨í•œ ì™¸ë¶€ ê²€ìƒ‰ ì—ì´ì „íŠ¸"""
        class SimpleExternalSearch:
            def search_external_knowledge(self, query: str, context: Dict = None, force_search: bool = False):
                # ì™¸ë¶€ ê²€ìƒ‰ì€ ì¼ë‹¨ ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ë‚˜ì¤‘ì— Perplexity ì—°ë™ ê°€ëŠ¥)
                class SearchResult:
                    def __init__(self):
                        self.content = f"ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ëŠ” í˜„ì¬ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‚´ë¶€ Knowledge Base ê²°ê³¼ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
                        self.sources = []
                        self.confidence = 0.1  # ë‚®ì€ ì‹ ë¢°ë„
                
                return SearchResult()
        
        return SimpleExternalSearch()
    
    def get_performance_metrics(self) -> Dict:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return self.performance_metrics.copy()
    
    def update_thresholds(self, new_thresholds: Dict[ThresholdType, float]):
        """ì„ê³„ê°’ ì—…ë°ì´íŠ¸"""
        for threshold_type, value in new_thresholds.items():
            if threshold_type in self.thresholds:
                self.thresholds[threshold_type] = value
                logger.info(f"ì„ê³„ê°’ ì—…ë°ì´íŠ¸: {threshold_type.value} = {value}")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    engine = ConditionalExecutionEngine()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        "ì‚¼ì–‘ì‹í’ˆ ì£¼ê°€ëŠ” ì–´ë–¤ê°€ìš”?",          # ë‚ ì§œ í‘œí˜„ ì—†ìŒ â†’ ìµœì‹ ìˆœ
        "1ë…„ ì „ ì‚¼ì„±ì „ìëŠ” ì–´ë• ë‚˜ìš”?",        # ë‚ ì§œ í‘œí˜„ ìˆìŒ â†’ ë‚ ì§œ í•„í„°ë§
        "ìµœê·¼ ê²½ì œ ë™í–¥ ë¶„ì„í•´ì¤˜",            # ë³µì¡í•œ ì§ˆë¬¸ â†’ ì™¸ë¶€ ê²€ìƒ‰
        "ë°˜ë„ì²´?"                           # ì• ë§¤í•œ ì§ˆë¬¸ â†’ ì¬ì§ˆë¬¸
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*50}")
        print(f"í…ŒìŠ¤íŠ¸ {i}: {query}")
        print('='*50)
        
        result = engine.execute_workflow(
            query=query,
            user_context={"user_id": f"test_user_{i}"},
            execution_options={"debug": True}
        )
        
        print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶œë ¥
    print(f"\n{'='*50}")
    print("ì„±ëŠ¥ ë©”íŠ¸ë¦­")
    print('='*50)
    metrics = engine.get_performance_metrics()
    print(json.dumps(metrics, ensure_ascii=False, indent=2)) 