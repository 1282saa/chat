"""
APAC Claude ëª¨ë¸ ì¤‘ì•™ ê´€ë¦¬ì
- ì„œìš¸ ë¦¬ì „ ìµœì í™” ëª¨ë¸ ê´€ë¦¬
- ì„±ëŠ¥ ê¸°ë°˜ ë™ì  ëª¨ë¸ ì„ íƒ
- ë¹„ìš© íš¨ìœ¨ì„± ê³ ë ¤
- ì˜¤ë¥˜ ì²˜ë¦¬ ë° í´ë°± ë¡œì§
"""

import os
import logging
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass

logger = logging.getLogger()
logger.setLevel(logging.INFO)

@dataclass
class ModelInfo:
    """APAC ëª¨ë¸ ì •ë³´"""
    model_id: str
    name: str
    avg_response_time: float
    cost_per_1k_tokens: float
    max_tokens: int
    specialties: List[str]
    recommended_use: str

class APACModelManager:
    """
    APAC ì§€ì—­ Claude ëª¨ë¸ ì¤‘ì•™ ê´€ë¦¬ì
    ì„œìš¸ ë¦¬ì „ì—ì„œ í…ŒìŠ¤íŠ¸ëœ ì„±ëŠ¥ ë°ì´í„° ê¸°ë°˜
    """
    
    def __init__(self):
        """APAC ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸ëœ APAC ëª¨ë¸ ì •ë³´ (ì„œìš¸ ë¦¬ì „ ê¸°ì¤€)
        self.models = {
            "fast": ModelInfo(
                model_id="apac.anthropic.claude-3-haiku-20240307-v1:0",
                name="Claude 3 Haiku (APAC)",
                avg_response_time=1.89,
                cost_per_1k_tokens=0.25,
                max_tokens=200000,
                specialties=["ë¹ ë¥¸_ì‘ë‹µ", "ê°„ë‹¨_ì§ˆë¬¸", "ì‹¤ì‹œê°„_ì²˜ë¦¬"],
                recommended_use="ê°„ë‹¨í•œ ì§ˆë¬¸, ë¹ ë¥¸ ì‘ë‹µ í•„ìš”ì‹œ"
            ),
            "balanced": ModelInfo(
                model_id="apac.anthropic.claude-3-sonnet-20240229-v1:0",
                name="Claude 3 Sonnet (APAC)",
                avg_response_time=3.22,
                cost_per_1k_tokens=3.0,
                max_tokens=200000,
                specialties=["ê· í˜•", "ì¼ë°˜_ì§ˆë¬¸", "ì•ˆì •ì„±"],
                recommended_use="ì¼ë°˜ì ì¸ ì§ˆë¬¸, ê· í˜•ì¡íŒ ì„±ëŠ¥"
            ),
            "advanced": ModelInfo(
                model_id="apac.anthropic.claude-3-7-sonnet-20250219-v1:0",
                name="Claude 3.7 Sonnet (APAC)",
                avg_response_time=4.17,
                cost_per_1k_tokens=3.0,
                max_tokens=200000,
                specialties=["ìµœì‹ _ê¸°ìˆ ", "ì •í™•ì„±", "ë³µì¡_ë¶„ì„"],
                recommended_use="ë³µì¡í•œ ë¶„ì„, ìµœì‹  ê¸°ìˆ  í™œìš©"
            ),
            "high_performance": ModelInfo(
                model_id="apac.anthropic.claude-3-5-sonnet-20240620-v1:0",
                name="Claude 3.5 Sonnet (APAC)",
                avg_response_time=3.92,
                cost_per_1k_tokens=3.0,
                max_tokens=200000,
                specialties=["ê³ ì„±ëŠ¥", "ì°½ì˜ì„±", "ë³µì¡_ì¶”ë¡ "],
                recommended_use="ê³ í’ˆì§ˆ ë‹µë³€, ì°½ì˜ì  ì‘ì—…"
            ),
            "premium": ModelInfo(
                model_id="apac.anthropic.claude-sonnet-4-20250514-v1:0",
                name="Claude Sonnet 4 (APAC)",
                avg_response_time=4.48,
                cost_per_1k_tokens=15.0,
                max_tokens=200000,
                specialties=["ìµœê³ _í’ˆì§ˆ", "ì „ë¬¸_ë¶„ì„", "ì •í™•ì„±"],
                recommended_use="ì „ë¬¸ì  ë¶„ì„, ìµœê³  í’ˆì§ˆ í•„ìš”ì‹œ"
            ),
            "latest": ModelInfo(
                model_id="apac.anthropic.claude-3-5-sonnet-20241022-v2:0",
                name="Claude 3.5 Sonnet v2 (APAC)",
                avg_response_time=5.78,
                cost_per_1k_tokens=3.0,
                max_tokens=200000,
                specialties=["ìµœì‹ _ê¸°ëŠ¥", "í–¥ìƒëœ_ì¶”ë¡ ", "ë©€í‹°ëª¨ë‹¬"],
                recommended_use="ìµœì‹  ê¸°ëŠ¥ í™œìš©, ë³µí•© ì‘ì—…"
            )
        }
        
        # ì„±ëŠ¥ ìˆœìœ„ (ì†ë„ ê¸°ì¤€)
        self.speed_ranking = ["fast", "high_performance", "balanced", "advanced", "premium", "latest"]
        
        # í’ˆì§ˆ ìˆœìœ„ (ì„±ëŠ¥ ê¸°ì¤€)
        self.quality_ranking = ["premium", "latest", "advanced", "high_performance", "balanced", "fast"]
        
        # ë¹„ìš© íš¨ìœ¨ì„± ìˆœìœ„
        self.cost_efficiency_ranking = ["fast", "balanced", "high_performance", "advanced", "latest", "premium"]
        
        logger.info(f"ğŸ¯ APACModelManager ì´ˆê¸°í™” ì™„ë£Œ - {len(self.models)}ê°œ ëª¨ë¸ ê´€ë¦¬")
    
    def get_model_by_tier(self, tier: str) -> Optional[ModelInfo]:
        """í‹°ì–´ë³„ ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return self.models.get(tier)
    
    def get_model_id(self, tier: str) -> str:
        """í‹°ì–´ë³„ ëª¨ë¸ ID ë°˜í™˜"""
        model_info = self.models.get(tier)
        if model_info:
            return model_info.model_id
        return self.models["fast"].model_id  # ê¸°ë³¸ê°’
    
    def select_optimal_model(self, 
                           complexity: str = "medium",
                           priority: str = "balance", 
                           budget_tier: str = "standard",
                           max_response_time: float = None) -> Tuple[str, ModelInfo]:
        """
        ìµœì  ëª¨ë¸ ì„ íƒ
        
        Args:
            complexity: low/medium/high/expert
            priority: speed/balance/quality/cost
            budget_tier: economy/standard/premium
            max_response_time: ìµœëŒ€ í—ˆìš© ì‘ë‹µ ì‹œê°„(ì´ˆ)
        
        Returns:
            (model_tier, ModelInfo)
        """
        
        # 1. ë³µì¡ë„ë³„ í›„ë³´ ëª¨ë¸
        complexity_candidates = {
            "low": ["fast", "balanced"],
            "medium": ["balanced", "high_performance", "fast"],
            "high": ["advanced", "high_performance", "premium"],
            "expert": ["premium", "latest", "advanced"]
        }
        
        candidates = complexity_candidates.get(complexity, ["balanced"])
        
        # 2. ì˜ˆì‚° í‹°ì–´ë³„ í•„í„°ë§
        if budget_tier == "economy":
            candidates = [c for c in candidates if c in ["fast", "balanced"]]
        elif budget_tier == "standard":
            candidates = [c for c in candidates if c not in ["premium"]]
        # premium: ëª¨ë“  ëª¨ë¸ í—ˆìš©
        
        # 3. ì‘ë‹µ ì‹œê°„ ì œí•œ ì ìš©
        if max_response_time:
            candidates = [c for c in candidates 
                         if self.models[c].avg_response_time <= max_response_time]
        
        # 4. ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        if priority == "speed":
            ranking = self.speed_ranking
        elif priority == "quality":
            ranking = self.quality_ranking
        elif priority == "cost":
            ranking = self.cost_efficiency_ranking
        else:  # balance
            ranking = ["balanced", "high_performance", "fast", "advanced", "latest", "premium"]
        
        # 5. ìµœì  ëª¨ë¸ ì„ íƒ
        for tier in ranking:
            if tier in candidates:
                selected_model = self.models[tier]
                logger.info(f"ğŸ¯ ëª¨ë¸ ì„ íƒ: {tier} ({selected_model.name}) - "
                           f"ë³µì¡ë„={complexity}, ìš°ì„ ìˆœìœ„={priority}, ì˜ˆì‚°={budget_tier}")
                return tier, selected_model
        
        # 6. í´ë°±: ê¸°ë³¸ ëª¨ë¸
        fallback_tier = "fast"
        fallback_model = self.models[fallback_tier]
        logger.warning(f"âš ï¸ ì¡°ê±´ì— ë§ëŠ” ëª¨ë¸ ì—†ìŒ, ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {fallback_tier}")
        return fallback_tier, fallback_model
    
    def get_model_for_task(self, task_type: str) -> Tuple[str, ModelInfo]:
        """
        ì‘ì—… ìœ í˜•ë³„ ìµœì  ëª¨ë¸ ì¶”ì²œ
        
        Args:
            task_type: synthesis/analysis/planning/search/classification
        """
        
        task_mappings = {
            "synthesis": ("balanced", "ê· í˜•ì¡íŒ ë‹µë³€ ìƒì„±"),
            "analysis": ("advanced", "ì‹¬ì¸µ ë¶„ì„ í•„ìš”"),
            "planning": ("fast", "ë¹ ë¥¸ ê³„íš ìˆ˜ë¦½"),
            "search": ("fast", "ë¹ ë¥¸ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬"),
            "classification": ("fast", "ë¹ ë¥¸ ë¶„ë¥˜"),
            "expert_analysis": ("premium", "ì „ë¬¸ì  ë¶„ì„"),
            "creative": ("high_performance", "ì°½ì˜ì  ì‘ì—…"),
            "latest_features": ("latest", "ìµœì‹  ê¸°ëŠ¥ í™œìš©")
        }
        
        tier, reason = task_mappings.get(task_type, ("balanced", "ê¸°ë³¸ ì‘ì—…"))
        model_info = self.models[tier]
        
        logger.info(f"ğŸ“‹ ì‘ì—…ë³„ ëª¨ë¸ ì„ íƒ: {task_type} â†’ {tier} ({reason})")
        return tier, model_info
    
    def get_all_models(self) -> Dict[str, ModelInfo]:
        """ëª¨ë“  ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return self.models
    
    def get_model_comparison(self) -> Dict[str, Dict]:
        """ëª¨ë¸ ë¹„êµ ì •ë³´ ë°˜í™˜"""
        comparison = {}
        
        for tier, model in self.models.items():
            comparison[tier] = {
                "name": model.name,
                "model_id": model.model_id,
                "response_time": f"{model.avg_response_time}ì´ˆ",
                "cost": f"${model.cost_per_1k_tokens}/1K í† í°",
                "specialties": model.specialties,
                "recommended_use": model.recommended_use
            }
        
        return comparison
    
    def validate_model_availability(self, model_id: str) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        available_models = [model.model_id for model in self.models.values()]
        return model_id in available_models
    
    def get_environment_config(self) -> Dict[str, str]:
        """í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ëª¨ë¸ ì„¤ì • ë°˜í™˜"""
        return {
            "synthesizer_tier": os.environ.get("SYNTHESIZER_MODEL_TIER", "fast"),
            "react_tier": os.environ.get("REACT_MODEL_TIER", "fast"),
            "priority": os.environ.get("SYNTHESIS_PRIORITY", "balance"),
            "apac_enabled": os.environ.get("APAC_MODELS_ENABLED", "true").lower() == "true"
        }

# ì „ì—­ ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
model_manager = APACModelManager()

def get_model_manager() -> APACModelManager:
    """ê¸€ë¡œë²Œ ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return model_manager 