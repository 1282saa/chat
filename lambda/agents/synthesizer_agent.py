"""
ë‹µë³€ í•©ì„± ì—ì´ì „íŠ¸ (SynthesizerAgent)
- ê²€ìƒ‰ ê²°ê³¼ ì¢…í•© ë° Few-shot ê¸°ë°˜ ë‹µë³€ ìƒì„±
- MZì„¸ëŒ€ ìµœì í™” ë‹µë³€ í˜•ì‹
- ì¸ìš© ë²ˆí˜¸ ìë™ ì‚½ì… ë° ì¶œì²˜ ê²€ì¦
- í’ˆì§ˆ ë³´ì¥ ë° ì¼ê´€ì„± ê´€ë¦¬
"""
import json
import os
import re
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import boto3
from dataclasses import dataclass

logger = logging.getLogger()
logger.setLevel(logging.INFO)

@dataclass
class SynthesisResult:
    """ë‹µë³€ í•©ì„± ê²°ê³¼"""
    answer: str
    sources: List[Dict]
    quality_score: float
    word_count: int
    citation_count: int
    confidence: float
    metadata: Dict

class SynthesizerAgent:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸
    """
    
    def __init__(self):
        # Bedrock í´ë¼ì´ì–¸íŠ¸
        self.bedrock_client = boto3.client("bedrock-runtime", region_name="ap-northeast-2")
        
        # APAC ì§€ì—­ Claude ëª¨ë¸ ì„¤ì • (ì„œìš¸ ë¦¬ì „ ìµœì í™”)
        self.apac_models = {
            "fast": "apac.anthropic.claude-3-haiku-20240307-v1:0",          # 1.89ì´ˆ - ë¹ ë¥¸ ì‘ë‹µ
            "balanced": "apac.anthropic.claude-3-sonnet-20240229-v1:0",     # 3.22ì´ˆ - ê· í˜•
            "advanced": "apac.anthropic.claude-3-7-sonnet-20250219-v1:0",   # 4.17ì´ˆ - 2025ë…„ ìµœì‹ 
            "high_performance": "apac.anthropic.claude-3-5-sonnet-20240620-v1:0",  # 3.92ì´ˆ - ê³ ì„±ëŠ¥
            "premium": "apac.anthropic.claude-sonnet-4-20250514-v1:0",      # 4.48ì´ˆ - ìµœê³ ê¸‰
            "latest": "apac.anthropic.claude-3-5-sonnet-20241022-v2:0"      # 5.78ì´ˆ - ìµœì‹  v2
        }
        
        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì ˆ ê°€ëŠ¥)
        model_tier = os.environ.get("SYNTHESIZER_MODEL_TIER", "fast")  # fast/balanced/advanced/high_performance/premium/latest
        default_model = self.apac_models.get(model_tier, self.apac_models["fast"])
        
        self.model_config = {
            "model_id": default_model,
            "max_tokens": 3000,
            "temperature": 0.3,  # ì¼ê´€ì„± ìˆëŠ” ë‹µë³€
            "top_p": 0.9
        }
        
        # í’ˆì§ˆ ê¸°ì¤€
        self.quality_thresholds = {
            "min_word_count": 50,
            "max_word_count": 800,
            "min_citations": 1,
            "max_citations": 10,
            "confidence_minimum": 0.7
        }
        
        # Few-shot ë‹µë³€ ì˜ˆì‹œë“¤
        self.answer_examples = {
            "ì¼ë°˜": [
                {
                    "query": "ìµœê·¼ ê²½ì œ ìƒí™©ì€ ì–´ë–¤ê°€ìš”?",
                    "answer": "ìµœê·¼ ê²½ì œ ìƒí™©ì„ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\nì£¼ìš” ê²½ì œ ì§€í‘œë¥¼ ë³´ë©´ [1] ê´€ë ¨ ë‚´ìš©ì´ í™•ì¸ë©ë‹ˆë‹¤. íŠ¹íˆ [2] ë¶€ë¶„ì—ì„œ ì–¸ê¸‰ëœ ë°”ì™€ ê°™ì´ í˜„ì¬ ìƒí™©ì´ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ê²½ì œ ë™í–¥ì€ ì•ìœ¼ë¡œì˜ ì „ë§ì—ë„ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."
                },
                {
                    "query": "ê¸°ì—… ì‹¤ì ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                    "answer": "ê¸°ì—… ì‹¤ì  í˜„í™©ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n[1] ë³´ê³ ì„œì— ë”°ë¥´ë©´ ì£¼ìš” ê¸°ì—…ë“¤ì˜ ì‹¤ì ì´ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. [2] ë°ì´í„°ë¥¼ ì‚´í´ë³´ë©´ íŠ¹ì • ë¶„ì•¼ì—ì„œì˜ ì„±ê³¼ê°€ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.\n\nì „ë°˜ì ì¸ ê¸°ì—… ì‹¤ì  íë¦„ì„ ì¢…í•©í•˜ë©´ í˜„ì¬ ìƒí™©ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                }
            ],
            "ì •ì¹˜": [
                {
                    "query": "ìµœê·¼ ì •ì¹˜ ë™í–¥ì€ ì–´ë–¤ê°€ìš”?",
                    "answer": "ìµœê·¼ ì •ì¹˜ ë™í–¥ì— ëŒ€í•´ ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n[1] ê´€ë ¨ ë³´ë„ì— ë”°ë¥´ë©´ ì£¼ìš” ì •ì¹˜ì  ì´ìŠˆë“¤ì´ ë…¼ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤. [2] ì •ì¹˜ê¶Œì—ì„œëŠ” ì´ì™€ ê´€ë ¨í•˜ì—¬ ë‹¤ì–‘í•œ ì…ì¥ì´ í‘œëª…ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nì•ìœ¼ë¡œì˜ ì •ì¹˜ì  ì „ê°œ ê³¼ì •ì„ ì§€ì¼œë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
                },
                {
                    "query": "ì •ë¶€ ì •ì±… ë³€í™”ëŠ” ì–´ë–¤ê°€ìš”?",
                    "answer": "ì •ë¶€ ì •ì±… ë³€í™”ì— ëŒ€í•´ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n[1] ë°œí‘œëœ ì •ì±… ë‚´ìš©ì„ ë³´ë©´ ì£¼ìš” ë³€í™”ì‚¬í•­ì´ í™•ì¸ë©ë‹ˆë‹¤. [2] ê´€ë ¨ ë¶€ì²˜ì—ì„œëŠ” êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ì •ì±… ë³€í™”ê°€ ì‚¬íšŒ ê° ë¶„ì•¼ì— ë¯¸ì¹  ì˜í–¥ì„ ì£¼ëª©í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
                }
            ],
            "ê²½ì œ": [
                {
                    "query": "ì£¼ì‹ì‹œì¥ ë™í–¥ì€ ì–´ë–¤ê°€ìš”?",
                    "answer": "ì£¼ì‹ì‹œì¥ ë™í–¥ì— ëŒ€í•´ ë¶„ì„í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\n[1] ì‹œì¥ ë°ì´í„°ë¥¼ ë³´ë©´ ìµœê·¼ ì£¼ê°€ íë¦„ì´ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. [2] íˆ¬ììë“¤ì˜ ê´€ì‹¬ì‚¬í•­ê³¼ ê´€ë ¨í•˜ì—¬ ì£¼ìš” ì¢…ëª©ë“¤ì˜ ì›€ì§ì„ì´ í™•ì¸ë©ë‹ˆë‹¤.\n\nì „ì²´ì ì¸ ì‹œì¥ ìƒí™©ì„ ì¢…í•©í•˜ë©´ í˜„ì¬ì˜ íˆ¬ì í™˜ê²½ì„ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                }
            ]
        }
        
        logger.info(f"ğŸ¤– SynthesizerAgent ì´ˆê¸°í™” - ì‚¬ìš© ëª¨ë¸: {self.model_config['model_id']}")
    
    def select_optimal_model(self, complexity_level: str = "medium", priority: str = "speed") -> str:
        """
        ë³µì¡ë„ì™€ ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ìµœì  ëª¨ë¸ ì„ íƒ
        
        Args:
            complexity_level: low/medium/high/expert
            priority: speed/balance/quality
        """
        
        # ë³µì¡ë„ë³„ ëª¨ë¸ ë§¤í•‘
        complexity_models = {
            "low": ["fast", "balanced"],                           # ê°„ë‹¨í•œ ì§ˆë¬¸
            "medium": ["balanced", "high_performance"],           # ì¼ë°˜ì ì¸ ì§ˆë¬¸
            "high": ["advanced", "high_performance", "premium"],  # ë³µì¡í•œ ë¶„ì„ í•„ìš”
            "expert": ["premium", "latest"]                       # ì „ë¬¸ì  ë¶„ì„ í•„ìš”
        }
        
        # ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
        priority_order = {
            "speed": ["fast", "balanced", "high_performance", "advanced", "premium", "latest"],
            "balance": ["balanced", "high_performance", "fast", "advanced", "premium", "latest"],
            "quality": ["premium", "latest", "advanced", "high_performance", "balanced", "fast"]
        }
        
        # ì ì ˆí•œ ëª¨ë¸ ì„ íƒ
        available_models = complexity_models.get(complexity_level, ["balanced"])
        model_order = priority_order.get(priority, priority_order["balance"])
        
        # ì²« ë²ˆì§¸ë¡œ ì¡°ê±´ì— ë§ëŠ” ëª¨ë¸ ì„ íƒ
        for model_tier in model_order:
            if model_tier in available_models:
                selected_model = self.apac_models[model_tier]
                logger.info(f"ğŸ“Š ëª¨ë¸ ì„ íƒ: {model_tier} ({selected_model}) - ë³µì¡ë„: {complexity_level}, ìš°ì„ ìˆœìœ„: {priority}")
                return selected_model
        
        # ê¸°ë³¸ê°’
        return self.model_config["model_id"]
    
    def _analyze_complexity(self, query: str, sources: List[Dict]) -> str:
        """
        ì§ˆë¬¸ê³¼ ì†ŒìŠ¤ì˜ ë³µì¡ë„ ë¶„ì„
        
        Returns:
            "low" / "medium" / "high" / "expert"
        """
        
        complexity_score = 0
        
        # 1. ì§ˆë¬¸ ê¸¸ì´ ë° ë³µì¡ì„±
        if len(query) > 100:
            complexity_score += 1
        if any(keyword in query for keyword in ["ë¶„ì„", "ë¹„êµ", "ì „ë§", "ì˜ˆì¸¡", "í‰ê°€", "ìƒì„¸íˆ"]):
            complexity_score += 2
        if any(keyword in query for keyword in ["ì¢…í•©ì ìœ¼ë¡œ", "ì‹¬ì¸µì ìœ¼ë¡œ", "êµ¬ì²´ì ìœ¼ë¡œ", "ìì„¸íˆ"]):
            complexity_score += 1
            
        # 2. ì†ŒìŠ¤ ìˆ˜ì™€ ë‹¤ì–‘ì„±
        source_count = len(sources) if sources else 0
        if source_count > 5:
            complexity_score += 2
        elif source_count > 3:
            complexity_score += 1
            
        # 3. ì „ë¬¸ ìš©ì–´ ê°ì§€
        expert_keywords = ["EBITDA", "ESG", "DX", "AI", "ë°˜ë„ì²´", "ë©”íƒ€ë²„ìŠ¤", "NFT", "ì•”í˜¸í™”í", "ë¸”ë¡ì²´ì¸"]
        if any(keyword in query for keyword in expert_keywords):
            complexity_score += 1
            
        # 4. ìˆ˜ì¹˜ ë¶„ì„ ìš”êµ¬
        if any(keyword in query for keyword in ["%", "ì–µì›", "ì¡°ì›", "ë‹¬ëŸ¬", "ì¦ê°€", "ê°ì†Œ", "ìƒìŠ¹", "í•˜ë½"]):
            complexity_score += 1
            
        # ë³µì¡ë„ ë ˆë²¨ ê²°ì •
        if complexity_score >= 6:
            return "expert"
        elif complexity_score >= 4:
            return "high"
        elif complexity_score >= 2:
            return "medium"
        else:
            return "low"
        
        # Few-shot ì˜ˆì‹œ ë°ì´í„°ë² ì´ìŠ¤
        self.answer_examples = {
            "ê²½ì œ": [
                {
                    "query": "ì‚¼ì„±ì „ì ì£¼ê°€ ë™í–¥ì€?",
                    "sources": "ì‚¼ì„±ì „ìê°€ 3ë¶„ê¸° ì‹¤ì  ë°œí‘œì—ì„œ...(ì¶œì²˜1), ë°˜ë„ì²´ ì‹œì¥ íšŒë³µìœ¼ë¡œ...(ì¶œì²˜2)",
                    "answer": "ì‚¼ì„±ì „ì ì£¼ê°€ëŠ” ìµœê·¼ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. 3ë¶„ê¸° ì‹¤ì  ë°œí‘œì—ì„œ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ì‚¬ì—…ì´ ì˜ˆìƒë³´ë‹¤ ì¢‹ì€ ì„±ê³¼ë¥¼ ê±°ë‘ë©´ì„œ íˆ¬ììë“¤ì˜ ê´€ì‹¬ì´ ë†’ì•„ì¡ŒìŠµë‹ˆë‹¤[1]. \n\níŠ¹íˆ AIìš© ê³ ëŒ€ì—­í­ë©”ëª¨ë¦¬(HBM) ìˆ˜ìš” ì¦ê°€ì™€ í•¨ê»˜ ë°˜ë„ì²´ ì‹œì¥ ì „ë°˜ì˜ íšŒë³µ ì‹ í˜¸ê°€ ë‚˜íƒ€ë‚˜ê³  ìˆì–´ í–¥í›„ ì „ë§ë„ ê¸ì •ì ìœ¼ë¡œ í‰ê°€ë˜ê³  ìˆìŠµë‹ˆë‹¤[2]. ë‹¤ë§Œ ê¸€ë¡œë²Œ ê²½ì œ ë¶ˆí™•ì‹¤ì„±ì€ ì—¬ì „íˆ ë³€ìˆ˜ë¡œ ì‘ìš©í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.",
                    "reason": "ê²½ì œ ë‰´ìŠ¤ì— ëŒ€í•œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ ì˜ˆì‹œ"
                },
                {
                    "query": "ìµœê·¼ ê²½ì œ ë™í–¥ì€?",
                    "sources": "í•œêµ­ì€í–‰ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼...(ì¶œì²˜1), ë¬¼ê°€ìƒìŠ¹ë¥ ì´...(ì¶œì²˜2), ìˆ˜ì¶œì´...(ì¶œì²˜3)",
                    "answer": "ìµœê·¼ í•œêµ­ ê²½ì œëŠ” ì™„ë§Œí•œ íšŒë³µì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì€í–‰ì´ ê¸°ì¤€ê¸ˆë¦¬ë¥¼ ë™ê²°í•˜ë©´ì„œ í†µí™”ì •ì±…ì˜ ì•ˆì •ì„±ì„ ìœ ì§€í•˜ê³  ìˆê³ [1], ë¬¼ê°€ìƒìŠ¹ë¥ ë„ ì ì°¨ ì•ˆì •í™”ë˜ëŠ” ëª¨ìŠµì…ë‹ˆë‹¤[2].\n\nìˆ˜ì¶œ ë¶€ë¬¸ì—ì„œëŠ” ë°˜ë„ì²´ì™€ ìë™ì°¨ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê°œì„  íë¦„ì´ ë‚˜íƒ€ë‚˜ê³  ìˆì–´[3] ì „ë°˜ì ì¸ ê²½ê¸° íšŒë³µì— ê¸ì •ì ì¸ ì‹ í˜¸ë¡œ í•´ì„ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ë§Œ ëŒ€ì™¸ ê²½ì œ ì—¬ê±´ì˜ ë¶ˆí™•ì‹¤ì„±ì€ ì§€ì†ì ì¸ ê´€ì°°ì´ í•„ìš”í•œ ìƒí™©ì…ë‹ˆë‹¤.",
                    "reason": "ì¢…í•©ì ì¸ ê²½ì œ ìƒí™©ì— ëŒ€í•œ ê· í˜• ì¡íŒ ë¶„ì„ ì˜ˆì‹œ"
                }
            ],
            "ê¸°ì—…": [
                {
                    "query": "ë„¤ì´ë²„ ìµœê·¼ ì†Œì‹ì€?",
                    "sources": "ë„¤ì´ë²„ê°€ AI ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¥¼...(ì¶œì²˜1), ì›¹íˆ° ì‚¬ì—… í™•ì¥ì„...(ì¶œì²˜2)",
                    "answer": "ë„¤ì´ë²„ëŠ” ìµœê·¼ AI ê¸°ìˆ ì„ í™œìš©í•œ ìƒˆë¡œìš´ ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¥¼ ì„ ë³´ì´ë©° ì°¨ì„¸ëŒ€ í”Œë«í¼ìœ¼ë¡œì˜ ì „í™˜ì„ ê°€ì†í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤[1]. íŠ¹íˆ ìƒì„±í˜• AIë¥¼ ì ‘ëª©í•œ ê°œì¸í™” ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n\në˜í•œ ê¸€ë¡œë²Œ ì›¹íˆ° ì‹œì¥ì—ì„œì˜ ì…ì§€ë¥¼ ë”ìš± ê°•í™”í•˜ê¸° ìœ„í•´ í•´ì™¸ ìŠ¤íŠœë””ì˜¤ ì¸ìˆ˜ì™€ ì˜¤ë¦¬ì§€ë„ ì½˜í…ì¸  ì œì‘ì— ì ê·¹ì ìœ¼ë¡œ íˆ¬ìí•˜ê³  ìˆìŠµë‹ˆë‹¤[2]. ì´ëŸ¬í•œ ì›€ì§ì„ì€ êµ­ë‚´ë¥¼ ë„˜ì–´ ì•„ì‹œì•„ ì „ì²´ë¡œ ì‚¬ì—… ì˜ì—­ì„ í™•ì¥í•˜ë ¤ëŠ” ì „ëµìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.",
                    "reason": "ê¸°ì—… ë‰´ìŠ¤ì— ëŒ€í•œ ì „ëµì  ê´€ì  í¬í•¨ ë‹µë³€ ì˜ˆì‹œ"
                }
            ],
            "ì¼ë°˜": [
                {
                    "query": "ì˜¤ëŠ˜ ì£¼ìš” ë‰´ìŠ¤ëŠ”?",
                    "sources": "ì •ë¶€ê°€ ìƒˆë¡œìš´ ì •ì±…ì„...(ì¶œì²˜1), ë‚ ì”¨ê°€...(ì¶œì²˜2), ìŠ¤í¬ì¸ ì—ì„œ...(ì¶œì²˜3)",
                    "answer": "ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ì •ë¦¬í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\nì •ì¹˜ ë¶„ì•¼ì—ì„œëŠ” ì •ë¶€ê°€ ìƒˆë¡œìš´ ê²½ì œ í™œì„±í™” ì •ì±…ì„ ë°œí‘œí•˜ë©° ë¯¼ìƒ ê²½ì œ ì§€ì› ë°©ì•ˆì„ êµ¬ì²´í™”í–ˆìŠµë‹ˆë‹¤[1]. ì‚¬íšŒ ë¶„ì•¼ì—ì„œëŠ” ì „êµ­ì ìœ¼ë¡œ ìŒ€ìŒ€í•œ ë‚ ì”¨ê°€ ì´ì–´ì§€ë©´ì„œ ê±´ê°• ê´€ë¦¬ì— ì£¼ì˜ê°€ ë‹¹ë¶€ë˜ê³  ìˆìŠµë‹ˆë‹¤[2].\n\nìŠ¤í¬ì¸  ì†Œì‹ìœ¼ë¡œëŠ” í•œêµ­ ì„ ìˆ˜ë“¤ì´ êµ­ì œ ëŒ€íšŒì—ì„œ ì¢‹ì€ ì„±ê³¼ë¥¼ ê±°ë‘ë©° íŒ¬ë“¤ì—ê²Œ ê¸°ì¨ì„ ì„ ì‚¬í–ˆìŠµë‹ˆë‹¤[3]. ê° ë¶„ì•¼ë³„ë¡œ ë‹¤ì–‘í•œ ì†Œì‹ë“¤ì´ ì „í•´ì§€ê³  ìˆì–´ ê´€ì‹¬ ìˆëŠ” ì˜ì—­ì˜ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•´ë³´ì‹œê¸¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.",
                    "reason": "ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ë‰´ìŠ¤ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•œ ì˜ˆì‹œ"
                }
            ]
        }
        
        # MZì„¸ëŒ€ ìµœì í™” ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
        self.mz_style_guide = {
            "tone": "ì¹œê·¼í•˜ë©´ì„œë„ ì •í™•í•œ",
            "sentence_length": "2-3ì¤„ ë‚´ì™¸",
            "paragraph_style": "ë¹ˆ ì¤„ë¡œ ëª…í™•íˆ êµ¬ë¶„",
            "information_density": "í•µì‹¬ ì •ë³´ ì§‘ì¤‘",
            "engagement": "ê¶ê¸ˆì¦ í•´ì†Œ ì¤‘ì‹¬",
            "forbidden": ["ì´ëª¨ì§€", "íŠ¹ìˆ˜ê¸°í˜¸(**, ##)", "ê³¼ë„í•œ ìˆ˜ì‹ì–´"]
        }
    
    def synthesize_answer(self, 
                         query: str,
                         sources: List[Dict] = None,
                         external_context: List[Dict] = None,
                         synthesis_context: Dict = None,
                         search_results: Dict = None,
                         context: Dict = None) -> SynthesisResult:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
        """
        try:
            logger.info(f"ë‹µë³€ í•©ì„± ì‹œì‘: {query}")
            logger.info(f"ğŸ” ë°›ì€ sources íƒ€ì…: {type(sources)}, ê¸¸ì´: {len(sources) if sources else 0}")
            
            # ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° ìš°ì„  ì²˜ë¦¬
            if sources is not None and len(sources) > 0:
                # sourcesê°€ listë¡œ ì „ë‹¬ëœ ê²½ìš° dictë¡œ ë³€í™˜í•˜ì—¬ _process_search_results ì²˜ë¦¬
                search_results_dict = {"internal_result": {"content": "", "sources": sources, "confidence": 0.7}}
                processed_sources = self._process_search_results(search_results_dict)
                logger.info(f"âœ… Sources ì²˜ë¦¬ ì™„ë£Œ: {len(sources)}ê°œ")
            elif search_results is not None:
                processed_sources = self._process_search_results(search_results)
                logger.info(f"âœ… Search_results ì²˜ë¦¬ ì™„ë£Œ")
            else:
                processed_sources = {"combined_content": "", "source_list": [], "source_mix": {"internal": 0, "external": 0}, "total_confidence": 0.0}
                logger.warning("âš ï¸ ì²˜ë¦¬í•  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            # external_contextê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì²˜ë¦¬
            if external_context:
                # external_contextë„ ì ì ˆíˆ ì²˜ë¦¬
                for ext_item in external_context:
                    if isinstance(ext_item, dict):
                        processed_sources["combined_content"] += f"\nì™¸ë¶€ ì»¨í…ìŠ¤íŠ¸: {ext_item.get('content', '')}\n"
            
            # 2. ë‹µë³€ ì¹´í…Œê³ ë¦¬ ë° ë³µì¡ë„ ë¶„ì„
            if synthesis_context:
                category = synthesis_context.get("search_type", "ì¼ë°˜")
            elif context:
                category = context.get("category", "ì¼ë°˜")
            else:
                category = "ì¼ë°˜"
            
            # 3. ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„ ë° ëª¨ë¸ ì„ íƒ
            complexity_level = self._analyze_complexity(query, processed_sources["source_list"])
            priority = os.environ.get("SYNTHESIS_PRIORITY", "balance")  # speed/balance/quality
            selected_model = self.select_optimal_model(complexity_level, priority)
            
            logger.info(f"ë‹µë³€ ìƒì„± ì„¤ì •: ë³µì¡ë„={complexity_level}, ìš°ì„ ìˆœìœ„={priority}, ëª¨ë¸={selected_model}")
            
            # 4. Few-shot ì˜ˆì‹œ ì„ íƒ
            selected_examples = self._select_few_shot_examples(category, query)
            
            # 4. ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            synthesis_prompt = self._build_synthesis_prompt(
                query, processed_sources, selected_examples, context
            )
            
            # 5. Bedrockìœ¼ë¡œ ë‹µë³€ ìƒì„± (ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©)
            generated_answer = self._generate_answer_with_bedrock(synthesis_prompt, selected_model)
            
            # 6. ë‹µë³€ í›„ì²˜ë¦¬ ë° ê²€ì¦
            final_answer = self._post_process_answer(generated_answer, processed_sources)
            
            # 7. í’ˆì§ˆ í‰ê°€
            quality_metrics = self._evaluate_answer_quality(final_answer, processed_sources, query)
            
            # 8. ì¸ìš© ë²ˆí˜¸ ë° ì¶œì²˜ ì •ë¦¬
            citation_info = self._organize_citations(final_answer, processed_sources)
            
            result = SynthesisResult(
                answer=final_answer,
                sources=citation_info["sources"],
                quality_score=quality_metrics["overall_score"],
                word_count=quality_metrics["word_count"],
                citation_count=citation_info["citation_count"],
                confidence=quality_metrics["confidence"],
                metadata={
                    "category": category,
                    "examples_used": len(selected_examples),
                    "source_mix": processed_sources["source_mix"],
                    "generation_method": "few_shot_bedrock",
                    "processing_notes": quality_metrics.get("notes", []),
                    # APAC ëª¨ë¸ ì„ íƒ ì •ë³´ ì¶”ê°€
                    "selected_model": selected_model,
                    "complexity_level": complexity_level,
                    "model_priority": priority,
                    "model_tier": self._get_model_tier(selected_model)
                }
            )
            
            logger.info(f"ë‹µë³€ í•©ì„± ì™„ë£Œ - í’ˆì§ˆì ìˆ˜: {quality_metrics['overall_score']:.2f}, "
                       f"ì¸ìš©ìˆ˜: {citation_info['citation_count']}")
            
            return result
            
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"âŒ ë‹µë³€ í•©ì„± ì¤‘ ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
            logger.error(f"ğŸ“Š ì˜¤ë¥˜ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{error_details}")
            logger.error(f"ğŸ” ë””ë²„ê¹… ì •ë³´: sources={type(sources)}, external_context={type(external_context)}")
            return self._get_fallback_synthesis(query)
    
    def _process_search_results(self, search_results: Dict) -> Dict:
        """
        ê²€ìƒ‰ ê²°ê³¼ ì „ì²˜ë¦¬
        """
        processed = {
            "combined_content": "",
            "source_list": [],
            "source_mix": {"internal": 0, "external": 0},
            "total_confidence": 0.0
        }
        
        # ë‚´ë¶€ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        if search_results.get("internal_result"):
            internal = search_results["internal_result"]
            # SearchResult ê°ì²´ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸ í›„ ì²˜ë¦¬
            if hasattr(internal, 'content'):
                # SearchResult ê°ì²´ì¸ ê²½ìš°
                processed["combined_content"] += f"ë‚´ë¶€ ê²€ìƒ‰ ê²°ê³¼:\n{internal.content}\n\n"
                sources = internal.sources if hasattr(internal, 'sources') else []
                confidence = internal.confidence if hasattr(internal, 'confidence') else 0.0
            else:
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (Fallback)
                processed["combined_content"] += f"ë‚´ë¶€ ê²€ìƒ‰ ê²°ê³¼:\n{internal.get('content', '')}\n\n"
                sources = internal.get("sources", [])
                confidence = internal.get("confidence", 0.0)
            
            for i, source in enumerate(sources[:5], 1):
                # ë‚´ë¶€ ì†ŒìŠ¤ì— ë°œí–‰ì¼ ì •ë³´ í¬í•¨ (ë‰´ìŠ¤ ì„œë¹„ìŠ¤ í•„ìˆ˜)
                source_item = {
                    "index": i,
                    "type": "internal",
                    "content": source.get("content", "")[:300],
                    "metadata": source.get("metadata", {}),
                    "relevance": source.get("relevance", 0.0),
                    "published_date_raw": source.get("published_date_raw", ""),
                    "published_date_korean": source.get("published_date_korean", "ë°œí–‰ì¼ ë¯¸ìƒ"),
                    "has_date_info": source.get("has_date_info", False)
                }
                
                processed["source_list"].append(source_item)
                processed["source_mix"]["internal"] += 1
            
            processed["total_confidence"] += confidence * 0.6
        
        # ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        if search_results.get("external_result"):
            external = search_results["external_result"]
            # SearchResult ê°ì²´ì¸ì§€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸ í›„ ì²˜ë¦¬
            if hasattr(external, 'content'):
                # SearchResult ê°ì²´ì¸ ê²½ìš°
                processed["combined_content"] += f"ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼:\n{external.content}\n\n"
                sources = external.sources if hasattr(external, 'sources') else []
                confidence = external.confidence if hasattr(external, 'confidence') else 0.0
            else:
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (Fallback)
                processed["combined_content"] += f"ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼:\n{external.get('content', '')}\n\n"
                sources = external.get("sources", [])
                confidence = external.get("confidence", 0.0)
            
            start_index = len(processed["source_list"]) + 1
            for i, source in enumerate(sources[:5], start_index):
                processed["source_list"].append({
                    "index": i,
                    "type": "external",
                    "title": source.get("title", ""),
                    "url": source.get("url", ""),
                    "snippet": source.get("snippet", ""),
                    "relevance": source.get("relevance", 0.0)
                })
                processed["source_mix"]["external"] += 1
            
            processed["total_confidence"] += confidence * 0.4
        
        return processed
    
    def _select_few_shot_examples(self, category: str, query: str) -> List[Dict]:
        """
        Few-shot ì˜ˆì‹œ ì„ íƒ
        """
        # ì¹´í…Œê³ ë¦¬ë³„ ì˜ˆì‹œ ì„ íƒ
        category_examples = self.answer_examples.get(category, self.answer_examples["ì¼ë°˜"])
        
        # ì§ˆë¬¸ ìœ ì‚¬ì„± ê¸°ë°˜ ì„ íƒ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
        query_keywords = set(query.lower().split())
        
        scored_examples = []
        for example in category_examples:
            example_keywords = set(example["query"].lower().split())
            similarity = len(query_keywords & example_keywords) / len(query_keywords | example_keywords)
            scored_examples.append((similarity, example))
        
        # ìƒìœ„ 2ê°œ ì˜ˆì‹œ ì„ íƒ
        sorted_examples = sorted(scored_examples, key=lambda x: x[0], reverse=True)
        return [example for _, example in sorted_examples[:2]]
    
    def _build_synthesis_prompt(self, 
                               query: str, 
                               processed_sources: Dict, 
                               examples: List[Dict], 
                               context: Dict = None) -> str:
        """
        ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        """
        
        # í˜„ì¬ ë‚ ì§œ ì •ë³´ ìƒì„±
        from datetime import datetime
        import pytz
        
        kst = pytz.timezone('Asia/Seoul')
        current_time = datetime.now(kst)
        current_date_info = f"""
## ì¤‘ìš”: í˜„ì¬ ì‹œì  ì •ë³´
- ì˜¤ëŠ˜ ë‚ ì§œ: {current_time.strftime('%Yë…„ %mì›” %dì¼')} ({current_time.strftime('%A')})
- í˜„ì¬ ë…„ë„: {current_time.year}ë…„
- 1ë…„ ì „: {current_time.year - 1}ë…„
- 2ë…„ ì „: {current_time.year - 2}ë…„
- ì‘ë…„: {current_time.year - 1}ë…„

âš ï¸ ì¤‘ìš”: ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚ ì§œ ê´€ë ¨ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•˜ì„¸ìš”.
"""
        
        # Few-shot ì˜ˆì‹œ êµ¬ì„±
        example_text = ""
        for i, example in enumerate(examples, 1):
            # sources í‚¤ê°€ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            example_sources = example.get('sources', 'ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ ë° ë¶„ì„ ìë£Œ')
            example_text += f"""
ì˜ˆì‹œ {i}:
ì§ˆë¬¸: {example['query']}
ì£¼ì–´ì§„ ì •ë³´: {example_sources}
ë‹µë³€: {example['answer']}

"""
        
        # ë©”ì¸ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ ì„œìš¸ê²½ì œì‹ ë¬¸ì˜ ì „ë¬¸ ë‰´ìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì½ê¸° ì‰¬ìš´ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

{current_date_info}

## ğŸ“° ë‰´ìŠ¤ ì„œë¹„ìŠ¤ í•„ìˆ˜ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)

**ë‚ ì§œ ì •ë³´ í•„ìˆ˜ í¬í•¨:**
- ëª¨ë“  ì‚¬ì‹¤ì— êµ¬ì²´ì ì¸ ë‚ ì§œ ëª…ì‹œ (ë…„/ì›”/ì¼/ì‹œê°„)
- "ìµœì‹ ", "ìµœê·¼", "ë©°ì¹  ì „" ê°™ì€ ì• ë§¤í•œ í‘œí˜„ ê¸ˆì§€
- ì˜ˆ: "2025ë…„ 7ì›” 28ì¼ ì˜¤í›„ 2ì‹œ ë°œí‘œ", "7ì›” 27ì¼ ì˜¤ì „ 10ì‹œ 30ë¶„ ê³µì‹œ"
- S3 ë©”íƒ€ë°ì´í„°ì˜ ë°œí–‰ì¼ ì •ë³´ ë°˜ë“œì‹œ í™œìš©

**ì¶œì²˜ë³„ ë°œí–‰ ì‹œì  ëª…ì‹œ:**
- ê° ì¶œì²˜ì˜ ì •í™•í•œ ë°œí–‰ì¼ì‹œ í¬í•¨
- ì˜ˆ: "[1] 2025ë…„ 7ì›” 28ì¼ 14:30 - ì‚¼ì„±ì „ì ì‹¤ì  ë°œí‘œ"
- ì˜ˆ: "[2] 7ì›” 27ì¼ ì˜¤í›„ 3ì‹œ - í•˜ì´ë‹‰ìŠ¤ ì£¼ê°€ ê¸‰ë“± ì†Œì‹"

**ì •í™•ì„± ìš°ì„ :**
- ë°œí–‰ì¼ì´ ë¶ˆëª…í™•í•œ ì •ë³´ëŠ” "ë°œí–‰ì¼ ë¯¸ìƒ" ëª…ì‹œ
- ì¶”ì • ì •ë³´ëŠ” "ì¶”ì •" ë˜ëŠ” "ì˜ˆìƒ" ëª…ì‹œ
- ê³¼ê±° ì‚¬ì‹¤ì€ ì •í™•í•œ ê³¼ê±° ë‚ ì§œë¡œ í‘œê¸°

## ë‹µë³€ ì‘ì„± ê·œì¹™

**ìŠ¤íƒ€ì¼ ê°€ì´ë“œ:**
- MZì„¸ëŒ€ê°€ ì½ê¸° ì‰¬ìš´ ì¹œê·¼í•˜ë©´ì„œë„ ì •í™•í•œ í†¤
- ë¬¸ì¥ì€ 2-3ì¤„ ë‚´ì™¸ë¡œ ê°„ê²°í•˜ê²Œ
- ë¬¸ë‹¨ì€ ë¹ˆ ì¤„ë¡œ ëª…í™•íˆ êµ¬ë¶„
- í•µì‹¬ ì •ë³´ì— ì§‘ì¤‘í•˜ì—¬ ê¶ê¸ˆì¦ í•´ì†Œ
- ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ê¸°í˜¸(**, ##) ì‚¬ìš© ê¸ˆì§€

**ì¸ìš© ê·œì¹™:**
- ë°˜ë“œì‹œ ì¶œì²˜ ì •ë³´ë¥¼ [ìˆ«ì] í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- ê° ì£¼ìš” ì •ë³´ë§ˆë‹¤ í•´ë‹¹í•˜ëŠ” ì¶œì²˜ ë²ˆí˜¸ ì‚½ì…
- ì¸ìš© ë²ˆí˜¸ëŠ” ë¬¸ì¥ ëì— ë°°ì¹˜
- ì¶œì²˜ì— ë°œí–‰ì¼ì‹œ í¬í•¨

**ë‚´ìš© êµ¬ì„±:**
- 50-800ë‹¨ì–´ ë‚´ì™¸ë¡œ ì‘ì„±
- ê°ê´€ì  ì‚¬ì‹¤ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ 
- ì¶”ì¸¡ì´ë‚˜ ê°œì¸ ì˜ê²¬ ë°°ì œ
- êµ¬ì²´ì ì¸ ë‚ ì§œ, ìˆ˜ì¹˜, ì¸ëª…, ê¸°ê´€ëª… í¬í•¨

## Few-shot í•™ìŠµ ì˜ˆì‹œ

{example_text}

## ì‹¤ì œ ì‘ì—…

ì§ˆë¬¸: {query}

ì£¼ì–´ì§„ ê²€ìƒ‰ ê²°ê³¼:
{processed_sources['combined_content']}

ì¶œì²˜ ëª©ë¡:
{self._format_source_list(processed_sources['source_list'])}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ì¸ìš© ë²ˆí˜¸ë¥¼ í¬í•¨í•˜ê³ , MZì„¸ëŒ€ê°€ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        return prompt
    
    def _get_model_tier(self, model_id: str) -> str:
        """ëª¨ë¸ IDì—ì„œ tier ì´ë¦„ ì¶”ì¶œ"""
        for tier, tier_model_id in self.apac_models.items():
            if tier_model_id == model_id:
                return tier
        return "unknown"
    
    def _format_source_list(self, source_list: List[Dict]) -> str:
        """ì¶œì²˜ ëª©ë¡ í¬ë§·íŒ… (ë‰´ìŠ¤ ì„œë¹„ìŠ¤ìš© - ë°œí–‰ì¼ ì •ë³´ í¬í•¨)"""
        formatted_sources = []
        
        for source in source_list:
            if source["type"] == "internal":
                # ë‚´ë¶€ ì†ŒìŠ¤ì˜ ë°œí–‰ì¼ ì •ë³´ í¬í•¨
                published_date = source.get('published_date_korean', '')
                date_info = f" ({published_date})" if published_date and published_date != "ë°œí–‰ì¼ ë¯¸ìƒ" else " (ë°œí–‰ì¼ ë¯¸ìƒ)"
                
                formatted_sources.append(
                    f"[{source['index']}] ë‚´ë¶€ ë¬¸ì„œ{date_info}: {source['content'][:100]}..."
                )
            else:
                # ì™¸ë¶€ ì†ŒìŠ¤ (Perplexity ë“±)
                title = source.get('title', 'External Source')
                snippet = source.get('snippet', '')[:100]
                domain = source.get('domain', '')
                
                # ì™¸ë¶€ ì†ŒìŠ¤ë„ ê°€ëŠ¥í•˜ë©´ ë‚ ì§œ ì •ë³´ í¬í•¨
                if domain:
                    formatted_sources.append(
                        f"[{source['index']}] {title} ({domain}): {snippet}..."
                    )
                else:
                    formatted_sources.append(
                        f"[{source['index']}] {title}: {snippet}..."
                    )
        
        return "\n".join(formatted_sources)
    
    def _generate_answer_with_bedrock(self, prompt: str, model_id: str = None) -> str:
        """
        Bedrockì„ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„± (ë™ì  ëª¨ë¸ ì„ íƒ ì§€ì›)
        
        Args:
            prompt: ìƒì„±í•  í”„ë¡¬í”„íŠ¸
            model_id: ì‚¬ìš©í•  ëª¨ë¸ ID (Noneì´ë©´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
        """
        try:
            # ì‚¬ìš©í•  ëª¨ë¸ ê²°ì •
            selected_model = model_id or self.model_config["model_id"]
            
            body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": self.model_config["max_tokens"],
                "temperature": self.model_config["temperature"],
                "top_p": self.model_config["top_p"],
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
            
            logger.info(f"ğŸš€ ë‹µë³€ ìƒì„± ì‹œì‘: {selected_model}")
            
            response = self.bedrock_client.invoke_model(
                modelId=selected_model,
                body=json.dumps(body)
            )
            
            response_body = json.loads(response['body'].read())
            generated_text = response_body['content'][0]['text']
            
            logger.info(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(generated_text)}ì")
            
            return generated_text.strip()
            
        except Exception as e:
            logger.error(f"âŒ Bedrock ë‹µë³€ ìƒì„± ì˜¤ë¥˜ (ëª¨ë¸: {selected_model}): {str(e)}")
            
            # í´ë°±: ê¸°ë³¸ ëª¨ë¸ë¡œ ì¬ì‹œë„
            if model_id and model_id != self.model_config["model_id"]:
                logger.info(f"ğŸ”„ ê¸°ë³¸ ëª¨ë¸ë¡œ ì¬ì‹œë„: {self.model_config['model_id']}")
                return self._generate_answer_with_bedrock(prompt, self.model_config["model_id"])
            
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
    
    def _post_process_answer(self, raw_answer: str, processed_sources: Dict) -> str:
        """
        ë‹µë³€ í›„ì²˜ë¦¬
        """
        processed_answer = raw_answer
        
        # 1. ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±°
        processed_answer = re.sub(r'^ë‹µë³€:\s*', '', processed_answer)
        processed_answer = re.sub(r'^Answer:\s*', '', processed_answer)
        
        # 2. ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì •ë¦¬
        processed_answer = re.sub(r'\n{3,}', '\n\n', processed_answer)
        
        # 3. íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
        processed_answer = re.sub(r'\*\*([^*]+)\*\*', r'\1', processed_answer)  # **êµµê²Œ** ì œê±°
        processed_answer = re.sub(r'##\s*([^\n]+)', r'\1', processed_answer)    # ## ì œëª© ì œê±°
        processed_answer = re.sub(r'[ğŸ“–ğŸ“ŠğŸ“ˆğŸ“‰ğŸ’¡ğŸ”]', '', processed_answer)    # ì´ëª¨ì§€ ì œê±°
        
        # 4. ì¸ìš© ë²ˆí˜¸ ê²€ì¦ ë° ì •ë¦¬
        processed_answer = self._validate_citations(processed_answer, len(processed_sources["source_list"]))
        
        # 5. ë¬¸ë‹¨ ì •ë¦¬
        processed_answer = self._format_paragraphs(processed_answer)
        
        return processed_answer.strip()
    
    def _validate_citations(self, answer: str, source_count: int) -> str:
        """
        ì¸ìš© ë²ˆí˜¸ ê²€ì¦ ë° ì •ë¦¬
        """
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¸ìš© ë²ˆí˜¸ ì œê±°
        def replace_invalid_citation(match):
            citation_num = int(match.group(1))
            if 1 <= citation_num <= source_count:
                return match.group(0)
            else:
                return ""
        
        # [ìˆ«ì] í˜•ì‹ì˜ ì¸ìš© ë²ˆí˜¸ ê²€ì¦
        validated_answer = re.sub(r'\[(\d+)\]', replace_invalid_citation, answer)
        
        # ì¸ìš© ë²ˆí˜¸ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ ì¸ìš© ì¶”ê°€
        if not re.search(r'\[\d+\]', validated_answer) and source_count > 0:
            validated_answer += "[1]"
        
        return validated_answer
    
    def _format_paragraphs(self, answer: str) -> str:
        """
        ë¬¸ë‹¨ í˜•ì‹ ì •ë¦¬
        """
        # ë¬¸ì¥ ëì˜ ì¸ìš© ë²ˆí˜¸ ë’¤ì— ì ì ˆí•œ ê°„ê²© ë³´ì¥
        formatted = re.sub(r'(\[\d+\])([ê°€-í£a-zA-Z])', r'\1 \2', answer)
        
        # ë¬¸ë‹¨ êµ¬ë¶„ ì •ë¦¬
        paragraphs = formatted.split('\n\n')
        clean_paragraphs = []
        
        for para in paragraphs:
            clean_para = para.strip()
            if clean_para:
                clean_paragraphs.append(clean_para)
        
        return '\n\n'.join(clean_paragraphs)
    
    def _evaluate_answer_quality(self, answer: str, processed_sources: Dict, query: str) -> Dict:
        """
        ë‹µë³€ í’ˆì§ˆ í‰ê°€
        """
        metrics = {
            "word_count": len(answer.split()),
            "citation_count": len(re.findall(r'\[\d+\]', answer)),
            "paragraph_count": len(answer.split('\n\n')),
            "confidence": 0.5,  # ê¸°ë³¸ê°’
            "overall_score": 0.5,
            "notes": []
        }
        
        # ê¸¸ì´ í‰ê°€
        word_count = metrics["word_count"]
        if self.quality_thresholds["min_word_count"] <= word_count <= self.quality_thresholds["max_word_count"]:
            metrics["confidence"] += 0.2
        elif word_count < self.quality_thresholds["min_word_count"]:
            metrics["notes"].append("ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŒ")
        elif word_count > self.quality_thresholds["max_word_count"]:
            metrics["notes"].append("ë‹µë³€ì´ ë„ˆë¬´ ê¹€")
        
        # ì¸ìš© í‰ê°€
        citation_count = metrics["citation_count"]
        if self.quality_thresholds["min_citations"] <= citation_count <= self.quality_thresholds["max_citations"]:
            metrics["confidence"] += 0.2
        elif citation_count == 0:
            metrics["notes"].append("ì¸ìš© ì—†ìŒ")
        
        # ë‚´ìš© í’ˆì§ˆ í‰ê°€
        if any(keyword in answer.lower() for keyword in ["ë¶„ì„", "ì „ë§", "ë°œí‘œ", "ë³´ë„"]):
            metrics["confidence"] += 0.1
        
        # êµ¬ì¡° í‰ê°€
        if metrics["paragraph_count"] >= 2:
            metrics["confidence"] += 0.1  # ì ì ˆí•œ ë¬¸ë‹¨ êµ¬ì„±
        
        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        metrics["overall_score"] = min(metrics["confidence"], 1.0)
        
        return metrics
    
    def _organize_citations(self, answer: str, processed_sources: Dict) -> Dict:
        """
        ì¸ìš© ì •ë³´ ì •ë¦¬
        """
        citation_numbers = re.findall(r'\[(\d+)\]', answer)
        unique_citations = list(set(map(int, citation_numbers)))
        
        organized_sources = []
        for citation_num in sorted(unique_citations):
            if citation_num <= len(processed_sources["source_list"]):
                source = processed_sources["source_list"][citation_num - 1]
                organized_sources.append({
                    "citation_number": citation_num,
                    "type": source["type"],
                    "title": source.get("title", f"ì¶œì²˜ {citation_num}"),
                    "url": source.get("url", ""),
                    "snippet": source.get("snippet", source.get("content", ""))[:200]
                })
        
        return {
            "sources": organized_sources,
            "citation_count": len(unique_citations),
            "coverage": len(unique_citations) / len(processed_sources["source_list"]) if processed_sources["source_list"] else 0.0
        }
    
    def _get_fallback_synthesis(self, query: str) -> SynthesisResult:
        """Fallback ë‹µë³€ í•©ì„±"""
        fallback_answer = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{query}'ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        
        return SynthesisResult(
            answer=fallback_answer,
            sources=[],
            quality_score=0.0,
            word_count=len(fallback_answer.split()),
            citation_count=0,
            confidence=0.0,
            metadata={"fallback": True, "error": "synthesis_failed"}
        )
    
    def to_dict(self, synthesis_result: SynthesisResult) -> Dict:
        """SynthesisResultë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "answer": synthesis_result.answer,
            "sources": synthesis_result.sources,
            "quality_score": synthesis_result.quality_score,
            "word_count": synthesis_result.word_count,
            "citation_count": synthesis_result.citation_count,
            "confidence": synthesis_result.confidence,
            "metadata": synthesis_result.metadata
        }

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    synthesizer = SynthesizerAgent()
    
    # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼ (Mock)
    test_search_results = {
        "internal_result": {
            "content": "ì‚¼ì„±ì „ìê°€ 3ë¶„ê¸° ì‹¤ì ì—ì„œ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ë¶€ë¬¸ì´ ì˜ˆìƒë³´ë‹¤ ì¢‹ì€ ì„±ê³¼ë¥¼ ë³´ì˜€ë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.",
            "sources": [
                {
                    "content": "ì‚¼ì„±ì „ì 3ë¶„ê¸° ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ì‹¤ì  ê°œì„ ",
                    "metadata": {"published_date": "2024-10-25"},
                    "relevance": 0.9
                }
            ],
            "confidence": 0.8
        },
        "external_result": {
            "content": "AI ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€ë¡œ ì‚¼ì„±ì „ì ì£¼ê°€ê°€ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.",
            "sources": [
                {
                    "title": "ì‚¼ì„±ì „ì ì£¼ê°€ ìƒìŠ¹",
                    "url": "https://example.com/news1",
                    "snippet": "AI ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€ë¡œ ì£¼ê°€ ìƒìŠ¹"
                }
            ],
            "confidence": 0.7
        }
    }
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        {
            "query": "ì‚¼ì„±ì „ì ìµœê·¼ ì‹¤ì ì€?",
            "context": {"category": "ê¸°ì—…"}
        },
        {
            "query": "ê²½ì œ ë™í–¥ì€?",
            "context": {"category": "ê²½ì œ"}
        }
    ]
    
    for i, test_case in enumerate(test_queries, 1):
        print(f"\n{'='*80}")
        print(f"í…ŒìŠ¤íŠ¸ {i}: {test_case['query']}")
        print('='*80)
        
        result = synthesizer.synthesize_answer(
            test_case["query"],
            test_search_results,
            test_case.get("context")
        )
        
        result_dict = synthesizer.to_dict(result)
        print(json.dumps(result_dict, ensure_ascii=False, indent=2))
    
    print(f"\n{'='*80}")
    print("SynthesizerAgent í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print('='*80) 